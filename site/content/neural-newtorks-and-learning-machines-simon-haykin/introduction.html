<!DOCTYPE html>
<html lang="pt-br">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="../../../site/style.css">
    <title>Neural Networks and Learning Machines / Introdução</title>
</head>

<header class="breadcrumb" id="top">
    <nav>
        <a href="../../../index.html">Voltar à página inicial</a>
        <br/>
        <p>Networks and Learning Machines | 3<sup>a</sup> Edição</p>
        <p>Simon Haykin</p>
    </nav>
</header>

<body>
    <main>
        <h1># 1.2 Introdução (p. 1/46)</h1>
        <p><img src="https://img.shields.io/badge/Status-Escrevendo-grey?labelColor=5F9EA0"></p>

        <article>
            <h2 id="subtitulo_1">1. Definição de rede neural<sup> <a class="linknotas" href="#nota_1">[1]</a></sup></h2>
            <p>
                Desde o início, o estudo das redes neurais artificiais foi pautado pela observação de que tanto o cérebro humano quanto os computadores convencionais são sistemas de processamento de informações<sup><a class="linknotas" href="#nota_2">[2]</a></sup> e, por conseguinte, realizam trabalho computacional<sup><a class="linknotas" href="#nota_3">[3]</a></sup>.
                Não apenas seu funcionamento é bastante distinto, mas a capacidade computacional do cérebro - não só humano, mas também o de outros animais - supera, em muito, a dos computadores digitais.
            </p>
            <p id="subtitulo_1_nota_4">
                O cérebro é um sistema de processamento de informações complexo, não linear e paralelo<sup><a class="linknotas" href="#nota_4">[4]</a></sup>. 
                Suas estruturas fundamentais são os neurônios, organizados de modo a realizar tarefas computacionais, a exemplo do reconhecimento de padrões. Portanto, assim no cérebro como nas redes artificiais, os neurônios constituem as unidades de processamento da informação.
            </p>
            <p id="subtitulo_1_nota_5">A plasticidade<sup><a class="linknotas" href="#nota_5">[5]</a></sup>, característica que permite a adaptação do indivíduo ao ambiente em que está inserido, também é importante para as redes neurais artificiais.</p>
            <p>Em linhas gerais, pode-se dizer que uma rede neural artificial é um modelo computacional inspirado no modo como o cérebro realiza o processamento de informações. Nas palavras de Haykin (2009, p. 2), “[…] a neural network is a machine that is designed to model the way in which the brain performs a particular task or function of interest”.</p>
            <p id="subtitulo_1_nota_6">
                Já como definição formal, o autor dá às redes neurais, vistas como uma máquina adaptativa<sup><a class="linknotas" href="#nota_6">[6]</a></sup>, o seguinte conceito:
                <blockquote>
                <p>A neural network is a massively parallel distributed processor made up of simple processing units that has a natural propensity for storing experiential knowledge and making it available for use. It resembles the brain in two respects:</p>
                <ol>
                <li>Knowledge is acquired by the network from its environment through a learning process.</li>
                <li>Interneuron connection strengths, known as synaptic weights, are used to store the ac-<br>
                quired knowledge. (HAYKIN, 2009, p. 2)</li>
                </ol>
                </blockquote>
            </p>
            <p>
                Em português, conforme definição dada na edição anterior do livro:
                <blockquote>
                <p>Uma rede neural é um processador maciçamente paralelamente distribuído constituído de unidades de processamento simples, que tem uma propensão natural para armazenar conhecimento experimental e torná-lo disponível para uso. Ela se assemelha ao cérebro em dois aspectos:</p>
                <ol>
                <li>O conhecimento é adquirido pela rede a partir de seu ambiente através de um processo de aprendizagem.</li>
                <li>Forças de conexão entre os neurônios, conhecidas como pesos sinápticos, são utilizadas para armazenar o conhecimento adquirido. (HAYKIN, 2001, p. 28)</li>
                </ol>
                </blockquote>
            </p>
            <p>Assim, na medida do possível, as redes neurais artificiais assemelham-se e são modeladas à luz do cérebro humano [interconexão de unidades computacionais simples - neurônios - assim no cérebro biológico, como nas redes neurais artificiais].</p>
            <p>O processo de aprendizagem - <strong>algoritmo de aprendizagem</strong> - tradicionalmente aplicado em redes neurais consiste na <strong>modificação dos pesos sinápticos</strong> das conexões neuronais e deve necessariamente resultar em <strong>atividade computacional útil</strong>, ou seja, o alcance do objetivo almejado.</p>
            <p>A rede neural pode alterar sua própria estrutura (topologia).</p>
            <p id="subtitulo_1_nota_7">Conforme o autor, a técnica de modificação dos pesos sinápticos guarda muita similaridade com a teoria dos filtros adaptativos lineares (<em>linear adaptive filter theory</em>)<sup><a class="linknotas" href="#nota_7">[7]</a></sup>.</p>
            
            <h3 id="subtitulo_1_1">1.1 Benefícios das redes neurais</h3>
            <p>A capacidade computacional das redes neurais é resultado de sua estrutura massiva e paralelamente distribuída, bem como da habilidade de aprender e generalizar. “A generalização se refere ao fato de a rede neural produzir saídas adequadas para entradas que não estavam presentes durante o treinamento (aprendizagem). Estas duas capacidades de processamento de informação [aprender e generalizar] tornam possível para as redes neurais resolver problemas complexos (de grande escala) que são atualmente intratáveis.” (HAYKIN, 2001, p. 28) [da 2 edição, em português].</p>
            <blockquote>
            <p>A generalização se refere ao fato de a rede neural produzir saídas adequadas para entradas que não estavam presentes durante o treinamento (aprendizagem) (HAYKIN, 2001, p. 28).</p>
            </blockquote>
            <blockquote>
            <p>Generalization refers to the neural network`s production of reasonable outputs for inputs not encountered during training (learning) (HAYKIN, 2009, p. 2).</p>
            </blockquote>
            <p>São produzidas saídas (<em>outputs</em>) adequadas para as entradas (<em>inputs</em>) fornecidas - <em>good approximate solutions</em>, do original em inglês (Haykin, 2009). Atualmente, o problema grande e complexo deve ser decomposto em problemas menores, os quais redes neurais de propósito específico têm capacidade de resolver.</p>
            <p>Principais capacidades e propriedades das redes neurais artificiais (p. 2/6):</p>
            <ul>
            <li>Não linearidade (embora individualmente os neurônios artificiais possam ser lineares ou não lineares);</li>
            <li>Mapeamento de entrada e saída (na aprendizagem supervisionada);</li>
            <li>Adaptabilidade (capacidade de modificar os pesos sinápticos);
            <ul>
            <li><strong>Dilema estabilidade x plasticidade:</strong> “Para aproveitar todos os benefícios da adaptabilidade, as constantes de tempo principais do sistema devem ser grandes o suficiente para que o sistema ignore perturbações espúrias mas ainda assim serem suficientemente pequenas para responder a mudanças significativas no ambiente” (HAYKIN, 2001, p. 30).</li>
            </ul>
            </li>
            <li>Resposta a evidências (não apenas classificar o padrão adequadamente, mas informar o nível de confiabilidade da escolha, rejeitando ambiguidade);</li>
            <li>Informação contextualizada (“O conhecimento é representado pela própria estrutura e estado de ativação de uma rede neural.” (HAYKIN, 2001, p. 30));</li>
            <li>Tolerância a falhas (devido à sua estrutura massiva e paralelamente distribuída);</li>
            <li>Implementação em VSLI (<em>very-large-scale-integration</em>)<sup><a class="linknotas" href="#nota_8">[8]</a></sup>;</li>
            <li>Uniformidade de análise e projeto (&quot;[…] as redes neurais desfrutam de universalidade como processadores de informação&quot; (HAYKIN, 2001, p. 30));</li>
            <li>Analogia neurobiológica (motivadas por estruturas biológicas do cérebro humano).</li>
            </ul>
        </article>

        <article>
            <h2 id="subtitulo_2">2. O cérebro humano<sup><a class="linknotas" href="#nota_9">[9]</a></sup></h2>
            <p>O sistema nervoso humano pode ser visto como um sistema de três estágios, do qual fazem parte cérebro, receptores e atuadores. Os estímulos - entrada (<em>input</em>) do sistema - são captados e convertidos em sinais elétricos pelos receptores; o cérebro continuamente recebe e processa esses sinais; os atuadores convertem os sinais recebidos de modo a gerar as ações (respostas) apropriadas, que constituem a saída (<em>output</em>) do sistema. A informação captada é transmitida em um único sentido - receptor &gt; cérebro &gt; atuador -, mas o sistema se retroalimenta no sentido oposto dessa transmissão - atuador &gt; cérebro &gt; receptor (<em>feedback</em>).</p>
            <p>Foi o trabalho de Santiago Ramón y Cajal que, em 1911, introduziu o neurônio como estrutura fundamental do cérebro. Os neurônios são cinco a seis ordens de grandeza mais lentos do que os circuitos digitais e, ainda assim, o cérebro é muito mais eficiente do que computadores em termos de eficiência energética. Provavelmente, isso é resultado da enorme quantidade de células neuronais e à massiva interconexão entre elas - a eficiência energética do cérebro humano é de <math><msup><mi>10</mi><mi>-16</mi></msup></math> joules por operação por segundo. Eles se apresentam sob diversas formas e tamanhos, sendo que um dos mais comuns é a denominada célula piramidal, e se organizam na anatomia cerebral em diversos níveis e em pequena ou grande escala.</p>
            <div class="image-container">
                <figure>
                    <img src="../../../imagens/01_celula_piramidal.png" alt="Célula piramidal">
                    <figcaption class="legenda">Figura 1 - Célula piramidal. Fonte: HAYKIN, 2009, p. 8.</figcaption>
                </figure>
            </div>
            <p>Essa estrutura hierárquica vai, em menor nível, das moléculas responsáveis pelas sinapses ao próprio sistema nervoso central, último nível hierárquico. A estrutura completa é apresentada por Haykin (2009, p. 9), na figura 3, da seguinte forma: moléculas &gt; sinapses &gt; microcircuitos neurais &gt; árvore dendrítica &gt; neurônio &gt; circuitos locais &gt; circuitos regionais &gt; sistema nervoso central.</p>
            <div class="image-container">
                <figure>
                    <img src="../../../imagens/02_cortex_cerebral.png" alt="Córtex cerebral">
                    <figcaption class="legenda">Figura 2 - Córtex cerebral. Fonte: HAYKIN, 2009, p. 10.</figcaption>
                </figure>
            </div>
            <blockquote>
            <p>The synapses represent the most fundamental level, depending on molecules and ions for their action. […] A neural microcircuit refers to an assembly of synapses organized into patterns of connectivity to produce a functional operation of interest. A neural microcircuit may be likened to a silicon chip made up of an assembly of transistors. At the next level of complexity, we have local circuits […] made up of neurons with similar or different properties; there neural assemblies perform operations characteristic of a localized region in the brain. They are followed by interregional circuits made up of pathways, columis, and topographic maps, which involve multiple regions located in different parts of the brain.<br>
            Topographic maps are organized to respond to incoming sensory information. These maps are often arranged in sheets, […] stacked in adjacent layers in such a way that stimuli from corresponding points in space lie above or below each other. […] different sensory inputs […] are mapped onto corresponding areas of the cerebral cortex in an orderly fashion. At the final level of complexity, the topographic maps and other interregional circuits mediate specific types of behavior in the central nervous system. (HAYKIN, 2009, p. 7/9)</p>
            </blockquote>
            <p>O equivalente, na 2 edição, em português:</p>
            <blockquote>
            <p>As sinapses representam o nível mais fundamental, dependente de moléculas e íons para sua ação. […] Um microcircuito neural se refere a um agrupamento de sinapses organizadas em padrões de conectividade para produzir uma operação funcional de interesse. Um microcircuito neural pode ser comparado a um circuito de silício constituído por um agrupamento de transistores. […] No nível seguinte de complexidade nós temos circuitos locais […] constituídos por neurônios com propriedades similares ou diferentes; estes agrupamentos neurais realizam operações características de uma região localizada no cérebro. Eles são seguidos por circuitos inter-regionais constituídos por caminhos, colunas e mapas topográficos, que envolvem regiões múltiplas localizadas em partes diferentes do cérebro.<br>
            Os mapas topográficos são organizados para responder à informação sensorial incidente. Estes mapas são frequentemente arranjados em folhas, […] empilhados em camadas adjacentes de tal modo que estímulos advindos de pontos correspondentes no espaço se localizem acima ou abaixo de cada um deles. […] diferentes entradas sensoriais […] são mapeadas sobre áreas correspondentes do córtex cerebral de forma ordenada. No nível final de complexidade, os mapas topográficos e outros circuitos inter-regionais medeiam tipos específicos de comportamento no sistema nervoso central. (HAYKIN, 2001, p. 33/36)</p>
            </blockquote>
            <p id="subtitulo_1_1_notas_10_11">As sinapses são unidades estruturais e funcionais elementares responsáveis por intermediar a comunicação entre neurônios<sup><a class="linknotas" href="#nota_10">[10]</a></sup> e, em maioria, são químicas. Nelas, um sinal elétrico pré-sináptico é transformado em sinal químico pela liberação de neurotransmissores, e depois se converte novamente em sinal elétrico, pós-sináptico (Shepherd; Koch, 1990 <em>apud</em> Haykin, 2009). “Nas descrições tradicionais da organização neural, assume-se que uma sinapse é uma conexão simples que pode impor ao neurônio receptivo excitação ou inibição, mas não ambas.” (HAYKIN, 2001, p. 33). <strong>O surgimento de novas sinapses ou a modificação das já existentes são os mecanismos responsáveis pela plasticidade cerebral e, consequentemente, pela aprendizagem.</strong></p>
            <p>A saída (<em>output</em>) do processamento neuronal são, no mais das vezes, impulsos elétricos denominados <strong>potenciais de ação</strong><sup><a class="linknotas" href="#nota_11">[11]</a></sup> ou <strong><em>spikes</em></strong> - na 2 edição, em português, o termo é traduzido como <strong>impulso</strong>.</p>
        </article>

        <article>
            <h2 id="subtitulo_3">3. Modelos de neurônio [artificial]</h2>
            <p>Em sua forma mais rudimentar, o modelo de um neurônio artificial possui três elementos básicos: um <strong>conjunto de sinapses ou elos de ligação (<em>synapses or connecting links</em>)</strong>, cada um com seu próprio peso ou força (peso sináptico/<em>synaptic weight</em>)<sup><a class="linknotas" href="#nota_12">[12]</a></sup>; um <strong>somador (<em>adder</em>)</strong>; e uma <strong>função de ativação (<em>activation function</em>)</strong>.</p>
            <p>Eis a representação gráfica do modelo (HAYKIN, 2009, p. 11):
                <div class="image-container">
                    <figure>
                        <img src="../../../imagens/03_neuronio_artificial_nao_linear_basico.png" alt="Modelo de neurônio artificial">
                        <figcaption class="legenda">Figura 3 - Modelo de neurônio artificial não linear representado por diagrama em blocos. Fonte: HAYKIN, 2009, p. 11.</figcaption>
                    </figure>
                </div>
            </p>
            <p>Trata-se do modelo de um neurônio artificial não linear representado por diagrama em blocos. Como se verá até ao final desta seção, o diagrama em blocos é uma das formas de representar graficamente uma rede neural artificial.</p>
            <p>Depreende-se que um sinal de <strong>entrada</strong> - representado pela letra <math><mi>x</mi></math> - é direcionado à sinapse - representada pela letra <math><mi>j</mi></math> -, que está conectada ao neurônio - representado pela letra <math><mi>k</mi></math> - e que, por sua vez, possui um peso sináptico - representado pela letra <math><mi>w</mi></math>.</p>
            <p>Noutras palavras, considerados quaisquer índices, diz-se que “[…] um sinal <math><msub><mi>x</mi><mi>j</mi></msub></math> na entrada da sinapse <math><mi>j</mi></math> conectada ao neurônio <math><mi>k</mi></math> é multiplicada pelo peso sináptico <math><msub><mi>w</mi><mi>kj</mi></msub></math>. […] O primeiro índice se refere ao neurônio em questão e o segundo se refere ao terminal de entrada da sinapse à qual o peso se refere.” (HAYKIN, 2001, p. 36).</p>
            <p>O somatório dos sinais de entrada ponderados pelos pesos sinápticos de cada neurônio pode, ou não, executar a função de ativação, que visa “restringir a amplitude da saída de um neurônio. A função de ativação é também referida como <em>função restritiva</em> já que restringe (limita) o intervalo permissível de amplitude do sinal de saída a um valor finito. Tipicamente, o intervalo normalizado da amplitude da saída de um neurônio é escrito como o intervalo unitário fechado [0, 1] ou alternativamente [-1, 1]” (HAYKIN, 2001, p. 37). Na terminologia em inglês, a dita função restritiva é denominada <em>squashing function</em> (HAYKIN, 2009, p. 10).</p>
            <p>O resultado - saída/<em>output</em> - do cálculo realizado pelo somador (na figura, <em>summing junction</em>) descreve um <strong>combinador linear (<em>linear combiner</em>)</strong>, representado pela letra <math><mi>u</mi></math> (não aparece no modelo acima), que consiste na soma dos valores da entrada do sistema multiplicada pelo peso sináptico do neurônio.</p>
            <p>Pode ser considerado no cálculo o <strong><em>bias</em></strong> (<strong>viés</strong>, em tradução literal), que “tem o efeito de aumentar ou diminuir a entrada líquida da função de ativação, dependendo se ele é positivo ou negativo, respectivamente” (HAYKIN, 2001, p. 37). No modelo acima, é representado por <math><msub><mi>b</mi><mi>k</mi></msub></math>, do que se infere que <strong>cada neurônio pode ter um viés específico</strong>. Tem-se, ainda, que o <em>bias</em> aplica uma <strong>transformação afim</strong> (<em>affine transformation</em>, em inglês) <strong>à saída do somador, que equivale à entrada líquida da função de ativação.</strong></p>
            <p>A saída do combinador linear - <math><msub><mi>u</mi><mi>k</mi></msub></math> -, após a incidência do <em>bias</em> - <math><msub><mi>b</mi><mi>k</mi></msub></math> -, se for o caso, é a <strong>entrada líquida (<em>net input</em>) da função de ativação</strong>. Esta, por sua vez, é representada na imagem por <math><mi>&#x03C6;</mi><mo>(</mo><mo>&#x22C5;</mo><mo>)</mo></math> e sua aplicação resulta na saída (<em>output</em>) do próprio neurônio, representada pela letra <math><mi>y</mi></math>.</p>
            <p>Portanto, <strong>para o neurônio <math><mi>k</mi></math>, sua saída é dada por 
                <math>
                    <msub>
                        <mi>y</mi>
                        <mi>k</mi>
                    </msub>
                    <mo>=</mo>
                    <mi>&#x03C6;</mi>
                    <mo>(</mo>
                    <msub>
                        <mi>u</mi>
                        <mi>k</mi>
                    </msub>
                    <mo>+</mo>
                    <msub>
                        <mi>b</mi>
                        <mi>k</mi>
                    </msub>
                    <mo>)</mo>
                </math>
            , cujos parâmetros são a saída do combinador linear <math><msub><mi>u</mi><mi>k</mi></msub></math> e o <em>bias</em> do neurônio <math><msub><mi>b</mi><mi>k</mi></msub></math>.</strong></p>
            
            <p>Até aqui, a representação matemática do neurônio <math><mi>k</mi></math> é dada por:
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                        <mi>u</mi>
                        <mi>k</mi>
                    </msub>
                    <mo>=</mo>
                    <munderover>
                    <mo>&#x2211;</mo>
                    <mrow class="MJX-TeXAtom-ORD">
                        <mi>j</mi>
                        <mo>=</mo>
                        <mi>1</mi>
                    </mrow>
                    <mi>m</mi>
                    </munderover>
                    <msub>
                    <mi>w</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                        <mi>k</mi>
                        <mi>j</mi>
                    </mrow>
                    </msub>
                    <msub>
                    <mi>x</mi>
                    <mi>j</mi>
                    </msub>
                </math>

            e

                <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                        <mi>y</mi>
                        <mi>k</mi>
                    </msub>
                    <mo>=</mo>
                    <mi>&#x03C6;</mi>
                    <mo>(</mo>
                    <msub>
                        <mi>u</mi>
                        <mi>k</mi>
                    </msub>
                    <mo>+</mo>
                    <msub>
                        <mi>b</mi>
                        <mi>k</mi>
                    </msub>
                    <mo>)</mo>
                </math>
            </p>

            <p id="subtitulo_3_nota_13">
                A equação

                <math>
                    <msub>
                        <mi>v</mi>
                        <mi>k</mi>
                    </msub>
                    <mo>=</mo>
                    <msub>
                        <mi>u</mi>
                        <mi>k</mi>
                    </msub>
                    <mo>+</mo>
                    <msub>
                        <mi>b</mi>
                        <mi>k</mi>
                    </msub>
                </math>
                
            mostra que o <strong>campo local induzido (<em>induced local field</em>) ou potencial de ativação (<em>activation potential</em>)</strong><sup><a class="linknotas" href="#nota_13">[13]</a></sup>, representado pela letra <math><mi>v</mi></math>, do neurônio <math><mi>k</mi></math> tem correlação com a saída do combinador linear - <math><msub><mi>u</mi><mi>k</mi></msub></math> - e o <em>bias</em> - <math><msub><mi>b</mi><mi>k</mi></msub></math> -, de modo a deslocar o gráfico da equação a depender se o valor do <em>bias</em> é positivo ou negativo.
        </p>
            
            <h3>3.1 Tipos de funções de ativação</h3>
            <h4>3.1.1 Função de limiar ou limite (<em>threshold function</em>)</h4>
            <p>É empregada no modelo de McCulloch-Pitts, no qual “a saída de um neurônio assume o valor de 1, se o campo local induzido daquele neurônio é não-negativo, e 0 caso contrário.” (HAYKIN, 2001, p. 39). É um modelo determinístico.</p>
            <p>Em notação matemática, representa-se a função por
                <math display="block">
                    <mi>&#x03C6;</mi>
                    <mo>(</mo>
                    <mi>v</mi>
                    <mo>)</mo>
                    <mo>=</mo>
                    <mrow>
                      <mo>{</mo>
                      <mtable>
                        <mtr>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                          <mtd>
                            <mtext>se&nbsp;</mtext>
                            <mi>v</mi>
                            <mo>&#x2265;</mo>
                            <mn>0</mn>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                          <mtd>
                            <mtext>se&nbsp;</mtext>
                            <mi>v</mi>
                            <mo>&lt;</mo>
                            <mn>0</mn>
                          </mtd>
                        </mtr>
                      </mtable>
                    </mrow>
                </math>
            </p>
            <p>Para a saída <math><msub><mi>y</mi><mi>k</mi></msub></math> do neurônio, temos que
                <math display="block">
                    <msub>
                        <mi>y</mi>
                        <mi>k</mi>
                    </msub>
                    <mo>=</mo>
                    <mrow>
                      <mo>{</mo>
                      <mtable>
                        <mtr>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                          <mtd>
                            <mtext>se&nbsp;</mtext>
                            <mi>v</mi>
                            <mo>&#x2265;</mo>
                            <mn>0</mn>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                          <mtd>
                            <mtext>se&nbsp;</mtext>
                            <mi>v</mi>
                            <mo>&lt;</mo>
                            <mn>0</mn>
                          </mtd>
                        </mtr>
                      </mtable>
                    </mrow>
                </math>    
            </p>            
            <p>Para esse neurônio, o campo local induzido ou potencial de ativação é dado por
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                        <mi>v</mi>
                        <mi>k</mi>
                    </msub>
                    <mo>=</mo>
                    <munderover>
                    <mo>&#x2211;</mo>
                    <mrow class="MJX-TeXAtom-ORD">
                        <mi>j</mi>
                        <mo>=</mo>
                        <mi>1</mi>
                    </mrow>
                    <mi>m</mi>
                    </munderover>
                    <msub>
                    <mi>w</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                        <mi>k</mi>
                        <mi>j</mi>
                    </mrow>
                    </msub>
                    <msub>
                    <mi>x</mi>
                    <mi>j</mi>
                    </msub>
                    <mo>+</mo>
                    <msub>
                        <mi>b</mi>
                        <mi>k</mi>
                    </msub>
                </math>
            </p>

            <h4>3.1.2 Função sigmoide</h4>
            <p>É a mais comumente utilizada na construção de redes neurais. “Ela é definida como uma função estritamente crescente que exige um balanceamento adequado entre comportamento linear e não-linear” (HAYKIN, 2001, p. 40), de modo que pode assumir valores contínuos no intervalo <math><mo>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>]</mo></math>. Essa função é diferenciável.</p>
            <p>Nos casos em que seja interessante que os valores da função de ativação se estenda de <math><mn>-1</mn></math> a <math><mn>+1</mn></math>, em vez de <math><mn>0</mn></math> a <math><mn>+1</mn></math>, tem-se a denominada <strong>função sinal (<em>signum function</em>)</strong>, que obedece à regra
                <math display="block">
                    <mi>&#x03C6;</mi>
                    <mo>(</mo>
                    <mi>v</mi>
                    <mo>)</mo>
                    <mo>=</mo>
                    <mrow>
                      <mo>{</mo>
                      <mtable>
                        <mtr>
                          <mtd>
                            <mn>1</mn>
                          </mtd>
                          <mtd>
                            <mtext>se&nbsp;</mtext>
                            <mi>v</mi>
                            <mo>&gt;</mo>
                            <mn>0</mn>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mn>0</mn>
                          </mtd>
                          <mtd>
                            <mtext>se&nbsp;</mtext>
                            <mi>v</mi>
                            <mo>=</mo>
                            <mn>0</mn>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mn>-1</mn>
                          </mtd>
                          <mtd>
                            <mtext>se&nbsp;</mtext>
                            <mi>v</mi>
                            <mo>&lt;</mo>
                            <mn>0</mn>
                          </mtd>
                        </mtr>
                      </mtable>
                    </mrow>
                </math>
            </p>

            <p> e sua função sigmoide (função tangente hiperbólica) é dada por
                <math display="block">
                    <mi>&#x03C6;</mi>
                    <mo>(</mo>
                    <mi>v</mi>
                    <mo>)</mo>
                    <mo>=</mo>
                    <mi>tanh</mi>
                    <mo>(</mo>
                    <mi>v</mi>
                    <mo>)</mo>
                </math>
            </p>

            <h3 id="subtitulo_3_2">3.2 Modelo estocástico de neurônio</h3>
            <p>Adição de uma variável aleatória ao modelo de McCulloch-Pitts, que é determinístico, de modo a torná-lo estocástico, isto é, probabilístico. Isso porque um modelo estocástico de neurônio tenta predizer possíveis resultados (saídas) levando em consideração a existência de um ou mais parâmetros variáveis ao longo do tempo. Ao contrário, em um modelo determinístico, as saídas devem ser sempre as mesmas para os mesmos valores de entrada.</p>
            <p>Se <math><mi>x</mi></math> representar o estado de um neurônio, <math><mi>v</mi></math> o seu potencial de ativação e <math><mi>P</mi><mo>(</mo><mi>v</mi><mo>)</math> a probabilidade de <strong>disparo</strong>, isto é, de que <strong>ocorra mudança de estado</strong>, tem-se que
                <math display="block">
                    <mi>x</mi>
                    <mo>=</mo>
                    <mrow>
                      <mo>{</mo>
                      <mtable>
                        <mtr>
                          <mtd>
                            <mn>+1</mn>
                          </mtd>
                          <mtd>
                            <mtext>com probabilidade&nbsp;&nbsp;</mtext>
                            <mo>&#x2061;</mo>
                            <mi>P</mi>
                            <mo>(</mo>
                            <mi>v</mi>
                            <mo>)</mo>
                          </mtd>
                        </mtr>
                        <mtr>
                          <mtd>
                            <mn>-1</mn>
                          </mtd>
                          <mtd>
                            <mtext>com probabilidade&nbsp;&nbsp;</mtext>
                            <mo>&#x2061;</mo>
                            <mn>1</mn>
                            <mo>-</mo>
                            <mi>P</mi>
                            <mo>(</mo>
                            <mi>v</mi>
                            <mo>)</mo>
                          </mtd>
                        </mtr>
                      </mtable>
                    </mrow>
                </math>
                </p>
            <p>e que
                <math display="block">
                    <mi>P</mi>
                    <mo>(</mo>
                    <mi>v</mi>
                    <mo>)</mo>
                    <mo>=</mo>
                    <mfrac>
                      <mn>1</mn>
                      <mrow>
                        <mn>1</mn>
                        <mo>+</mo>
                        <ms>exp</ms>
                        <mo>(</mo>
                        <mo>&#x2212;</mo>
                        <mi>v</mi>
                        <mo>/</mo>
                        <mi>T</mi>
                        <mo>)</mo>
                      </mrow>
                    </mfrac>
                </math>
            </p>                
            <p>em que <math><mi>T</mi></math> é a dita <strong>pseudotemperatura</strong>, “[…] utilizada para controlar o nível de ruído e portanto a incerteza de disparar […] como um parâmetro que controle as flutuações térmicas que representam os efeitos do ruído sináptico. Note que quando <math><mi>T</mi><mo>&#x2192;</mo><mn>0</mn></math>, 
                o neurônio estocástico […] se reduz a uma forma sem ruído (i.e., determinística), que é o modelo de McCulloch-Pitts.” (HAYKIN, 2001, p. 41).</p>
        </article>

        <article>
            <h3 id="subtitulo_3_3">3.3 Redes neurais como grafos dirigidos<sup><a class="linknotas" href="#nota_14">[14]</a></sup><sup><a class="linknotas" href="#nota_15">[15]</a></sup></h3>
            <blockquote>
                <p>A signal-flow graph is a network of directed *links (branches)* that are interconnected at certain points called *nodes*. A typical node <math><mi>j</mi></math> has an associated node signal <math><msub><mi>x</mi><mi>j</mi></msub></math>. A typical directed link originates at node <math><mi>j</mi></math> and terminates on node <math><mi>k</mi></math>; it has an associated <em>transfer function</em>, or <em>transmittance</em>, that specifies the manner in which the signal <math><msub><mi>y</mi><mi>k</mi></msub></math> at node <math><mi>k</mi></math> dependes on the signal <math><msub><mi>x</mi><mi>j</mi></msub></math> at node <math><mi>j</mi></math>. (HAYKIN, 2009, p. 15)</p>
            </blockquote>
            <p>Na edição em português:</p>
            <blockquote>
                <p>Um grafo de fluxo de sinal é uma rede de elos (ramos) orientados que são interligados em certos pontos chamados nós. Um nó típico <math><mi>j</mi></math> tem um sinal nodal <math><msub><mi>x</mi><mi>j</mi></msub></math> associado. Um elo orientado típico origina-se no nó <math><mi>j</mi></math> e termina no nó <math><mi>k</mi></math>; ele tem uma <em>função de transferência</em> ou <em>transmitância</em> associada que especifica a maneira pela qual o sinal <math><msub><mi>y</mi><mi>k</mi></msub></math> no nó <math><mi>k</mi></math> depende do sinal <math><msub><mi>x</mi><mi>j</mi></msub></math> no nó <math><mi>j</mi></math>. (HAYKIN, 2001, p. 41)</p>
            </blockquote>
            <p>O fluxo dos sinais obedece a três regras básicas:</p>
                <ol>
                    <li>Um sinal flui ao longo de um elo somente no sentido definido pela seta do elo, distinguindo-se dois tipos de elos (links):
                        <ul>
                            <li>Elos sinápticos (synaptic links), regido por uma relação linear de entrada-saída (input-output);</li>
                            <li>Elos de ativação (activation links), regido por uma relação não-linear de entrada-saída.</li>
                        </ul>
                    </li>
                    <li>Um sinal nodal é igual à soma algébrica de todos os sinais que entram no nó pertinente via os elos incidentes.</li>
                    <li>O sinal de um nó é transmitido para cada elo de saída originário deste nó, sendo a transmissão inteiramente independente das funções de transferência dos elos de saída.</li>
                </ol>
                <p>A não-linearidade nos elos de ativação é fator limitante da utilização do modelo.</p>
                <p>O grafo de fluxo de sinal construído a partir dessas regras é o seguinte (HAYKIN, 2009, p. 17):</p>
                <div class="image-container">
                    <figure>
                        <img src="../../../imagens/04_grafo_fluxo_sinal.png" alt="Grafo de fluxo de sinal de um neurônio">
                        <figcaption class="legenda">Figura 4 - Grafo de fluxo de sinal de um neurônio</figcaption>
                    </figure>
                </div>
                <p>Com base no modelo acima, extrai-se a seguinte <strong>definição matemática de uma rede neural</strong> (HAYKIN, 2009, p. 16/17):</p>
                    <blockquote>
                        <p>A neural network is a directed graph consisting of nodes with interconnecting synaptic and activation links and is characterized by four properties:</p>
                        <ol>
                            <li>Each neuron is represented by a set of linear synaptic links, an externally applied bias, and a possibly nonlinear activation link. The bias is represented by a synaptic link connected to an input fixed at +1.</li>
                            <li>The synaptic links of a neuron weight their respective input signals.</li>
                            <li>The weighted sum of the input signals defines the induces local field of the neuron in question.</li>
                            <li>The activation link squashes the induced local field of the neuron to produce an output.</li>
                        </ol>
                    </blockquote>
                <p>Da edição anterior, em português (HAYKIN, 2001, p. 43):</p>
                    <blockquote>
                        <p>Uma rede neural é um grafo orientado constituído de nós com elos de interligação sinápticos e de ativação e é caracterizado por quatro propriedades:</p>
                        <ol>
                            <li>Cada neurônio é representado por um conjunto de elos sinápticos lineares, um bias aplicado externamente e um elo de ativação possivelmente não-linear. O bias é representado por um elo sináptico conectado a uma entrada fixada em +1.</li>
                            <li>Os elos sinápticos de um neurônio ponderam seus respectivos sinais de entrada.</li>
                            <li>A soma ponderada dos sinais de entrada define o campo local induzido do neurônio em questão.</li>
                            <li>O elo de ativação limita o campo local induzido do neurônio para produzir uma saída.</li>
                        </ol>
                    </blockquote>
                    <p>O grafo referido na figura 4 é dito <strong>completo</strong> porque descreve o fluxo do sinal entre os neurônios e dentro de cada neurônio. Por outro lado, diz-se que o grafo <strong>parcialmente completo</strong> é aquele que expõe apenas o fluxo inter-neuronal, caso em que é referido como <strong>grafo arquitetural (<em>architectural graph</em>)</strong>, pois expressa uma espécie de planta da rede neural.</p>
                    <div class="image-container">
                        <figure>
                            <img src="../../../imagens/05_grafo_arquitetural.png" alt="Grafo arquitetural">
                            <figcaption class="legenda">Figura 5 - Grafo arquitetural. Fonte: HAYKIN, 2009, p. 17</fi>
                        </figure>
                    </div>
                    <h3 id="subtitulo_3_4">3.4 As três representações gráficas de uma rede neural<sup><a class="linknotas" href="#nota_16">[16]</a></sup></h3>
                    <ul>
                        <li><strong>Diagrama em blocos (<em>block diagram</em>)</strong>, que oferece uma descrição funcional da rede, conforme a figura 3;</li>
                        <li><strong>Grafo de fluxo de sinal (<em>signal-flow graph</em>)</strong>, que oferece uma descrição completa do fluxo dos sinais entre os neurônios e dentro de cada neurônio da rede, conforme a figura 4;</li>
                        <li><strong>Grafo arquitetural (<em>architectural graph</em>)</strong>, que oferece uma descrição estrutural, como uma planta baixa da rede, conforme a figura 5.</li>
                    </ul>
        </article>

        <article>
            <h2 id="subtitulo_5">5. Feedback (Realimentação)</h2>
            <blockquote>
                <p>Feedback is said to exist in a dynamic system whenever the output of an element in the system influences in part the input applied to that particular element, thereby giving rise to one or more closed paths for the transmission of signals around the system. (HAYKIN, 2009, p. 18)</p>
            </blockquote>
            <p>Na edição em português:</p>
            <blockquote>
                <p>Dizemos que existe realimentação em um sistema dinâmico<sup><a class="linknotas" href="#nota_17">[17]</a></sup> sempre que a saída de um elemento no sistema influencia em parte a entrada aplicada àquele elemento particular, originando assim um ou mais de um caminho fechado para transmissão de sinais em torno do sistema. (HAYKIN, 2001, p. 44)</p>
            </blockquote>
            <p>Ocorre no sistema nervoso dos animais. Tem posição de destaque em redes neurais recorrentes (RNN - <em> recurrent neural networks</em>), embora a não linearidade das unidades de processamento prejudique sua aplicação.</p>
            <p>O comportamento dinâmico da rede é controlado pelo ajuste dos pesos sinápticos<sup><a class="linknotas" href="#nota_18">[18]</a></sup>, de modo que, se <math><mrow><mi>|w|</mi><mo><</mo><mn>1</mn></mrow></math>, o sinal de saída é <strong>exponencialmente convergente</strong> e a rede é dita <strong>estável</strong>; se <math><mrow><mi>|w|</mi><mo>&geq;</mo><mn>1</mn></mrow></math>, o sinal de saída é <strong>divergente</strong> e a rede é dita <strong>instável</strong>. Neste caso, se <math><mrow><mi>|w|</mi><mo>=</mo><mn>1</mn></mrow></math>, a divergência é <strong>linear</strong> e, se <math><mrow><mi>|w|</mi><mo>></mo><mn>1</mn></mrow></math>, <strong>exponencial</strong>.</p>
            <p>O grafo de fluxo de sinal que mostra o modelo mais simples de um sistema realimentado é o seguinte (HAYKIN, 2009, p. 19):
                <div class="image-container">
                    <figure>
                        <img src="../../../imagens/06_grafo_fluxo_sinal_realimentado_laco_unico.png" alt="Grafo de fluxo de sinal de um sistema realimentado com laço único">
                        <figcaption class="legenda">Figura 6 - Grafo de fluxo de sinal de um sistema realimentado com laço único.</figcaption>
                    </figure>
                </div>
            </p>
        </article>

        <article>
            <h2>6. Arquiteturas de redes neurais (<em>Network architectures</em>)</h2>
            <p>A forma de organização neuronal da rede é fortemente correlacionada ao algoritmo de aprendizagem utilizado para o treinamento. <strong>Só é considerado um neurônio, ou nó da camada, se houver trabalho computacional.</strong></p>
            <p>De modo geral, Haykin afirma que os padrões de arquitetura de redes neurais constituem três grandes categorias:</p>
            <ol>
                <li><strong><em>Single-Layer Feed-forward Networks</em></strong> (Redes alimentadas adiante com camada única);</li>
                <li><strong><em>Multilayer Feed-forward Networks</em></strong> (Redes alimentadas diretamente com múltiplas camadas); e</li>
                <li><strong><em>Recurrent Networks</em></strong> (Redes recorrentes).</li>
            </ol>

            <h3>6.1 Single-Layer Feed-forward Networks</h3>
            <p>Nas redes neurais em camadas, como o nome sugere, os neurônios são organizados em camadas.</p>
            <p>Este é o modelo arquitetural mais simples e é dito que possui uma única camada, em referência à própria camada de saída (<em>output layer</em>) dos neurônios, pois somente esta realiza atividade computacional. Não há camadas intermediárias escondidas (<em>hidden layers</em>) e é denominada <strong>alimentada adiante (<em>feed-forward</em>)</strong>, ou acíclica, porque o fluxo dos sinais é <strong>unidirecional</strong>, isto é, <strong>não há realimentação</strong>.</p>
            <div class="image-container">
                <figure>
                    <img src="../../../imagens/07_single_layer_feed_forward_network.png" alt="Single-Layer Feed-forward Network">
                    <figcaption class="legenda">Figura 7 - Single-Layer Feed-forward Network. Fonte: HAYKIN, 2009, p. 21</figcaption>
                </figure>
            </div>

            <h3>6.2 Multilayer Feed-forward Networks</h3>
            <p>Possui uma ou mais camadas ocultas (<em>hidden layers</em>), compostas por neurônios ou unidades ocultos(as), cuja função "[...] é intervir entre a entrada externa e a saída da rede de maneira útil" (HAYKIN, 2001, p. 47). A adição de mais camadas ocultas aumenta o poder computacional da rede.</p>
            <p>Nesse sentido, "<em>in a rather loose sense, the network acquires a global perspective despite its local connectivity, due to the extra set of synaptic connections and the extra dimension of neural interactions</em> (Churchland and Sejnowski, 1992)" (HAYKIN, 2009, p. 22).</p>
            <p>Da edição anterior, em português, extrai-se que "em um sentido bastante livre, a rede adquire uma perspectiva global apesar de sua conectividade local, devido ao conjunto extra de conexões sinápticas e da dimensão extra de interações neurais (Churchland e Sejnowski, 1992)" (HAYKIN, 2001, p. 47).</p>
            <p>Os nós da camada mais externa recebem os sinais de entrada e os direcionam à camada seguinte, isto é, a primeira camada oculta, que os processa e encaminha à próxima camada, seguindo-se assim sucessivamente, até que cheguem à camada de saída. Em regra, os sinais de entrada das camadas internas são limitados aos próprios sinais de saída da camada imediatamente anterior.</p>
            <p>Na imagem a seguir, tem-se um exemplo de rede neural com uma camada oculta composta por quatro neurônios, a qual é referida como uma rede 10-4-2, ou seja, 10 neurônios de entrada (fonte), 4 ocultos e 2 na camada de saída.</p>
            <div class="image-container">
                <figure>
                    <img src="../../../imagens/08_multi_layer_feed_forward_network.png" alt="Multilayer Feed-forward Network">
                    <figcaption class="legenda">Figura 8 - Multilayer Feed-forward Network. Fonte: HAYKIN, 2009, p. 22.</figcaption>
                </figure>
            </div>
            <p>Por conseguinte, uma rede com <math><mi>m</mi></math> nós de entrada, <math><msub><mi>h</mi><mn>1</mn></msub></math> neurônios na primeira camada oculta, <math><msub><mi>h</mi><mn>2</mn></msub></math> neurônios na segunda camada oculta e <math><mi>q</mi></math> neurônios na camada de saída é referida como uma rede <math><ms>m-</ms><msub><ms>h</ms><ms>1</ms></msub><msub><ms>-h</ms><ms>2</ms></msub><ms>-q</ms></math></p>
            <p>A rede apresentada na figura acima é dita <strong>totalmente conectada</strong> pois cada neurônio de uma camada está conectado a todos os neurônios da camada seguinte. Do contrário, se houvesse alguma conexão sináptica faltante, seria denominada <strong>parcialmente conectada</strong>.</p>
            
            <h3>6.3 Recurrent Networks</h3>
            <p>As redes modeladas neste estilo arquitetural possuem, pelo menos, um laço de realimentação (<em>feedback loop</em>). Essa característica reflete positivamente na capacidade de aprendizado e na performance da rede. Elas podem ou não ser auto-realimentadas (<em>self-feedback</em>), isto é, a saída de um neurônio pode ou não ser realimentada a sua própria entrada.</p>
            <p>Abaixo, está exemplificada uma rede neural recorrente sem auto-realimentação e sem neurônios ocultos:</p>
            <div class="image-container">
                <figure>
                    <img src="../../../imagens/09_recurrent_network_without_feedback.png" alt="Rede recorrente sem auto-realimentação e sem neurônios ocultos">
                    <figcaption class="legenda">Figura 9 - Rede recorrente sem auto-realimentação e sem neurônios ocultos. Fonte: HAYKIN, 2009, p. 23.</figcaption>
                </figure>
            </div>
            <p>Já a seguir, tem-se um exemplo de rede recorrente com neurônios ocultos:</p>
            <div class="image-container">
                <figure>
                    <img src="../../../imagens/10_recurrent_network_with_hidden_neurons.png" alt="Rede recorrente com neurônios ocultos">
                    <figcaption class="legenda">Figura 10 - Rede recorrente com neurônios ocultos. Fonte: HAYKIN, 2009, p. 24.</figcaption>
                </figure>
            </div>
            <p>Em ambos os casos, verifica-se a presença de elementos de atraso unitário (<em>unit-time delay elements</em>), representados por <math><msup><mi>z</mi><mn>-1</mn></msup></math>, nos laços de realimentação, com o objetivo de conferir comportamento dinâmico não-linear à rede.</p>
        </article>

        <article>
            <h2 id="subtitulo_7">7. Representação do conhecimento<sup> <a class="linknotas" href="#nota_19">[19]</a></sup></h2></h3>
            <p>"Knowledge refers to stored information or models used by a person or machine to interpret, predict, and appropriately respond to the outside world" (FISCHLER; FIRSCHEIN, 1987 apud HAYKIN, 2009, p. 24). Ou, na 2a edição, "Conhecimento se refere à informação armazenada ou a modelos utilizados por uma pessoa ou máquina para interpretar, prever e responder apropriadamente ao mundo exterior" (FISCHLER; FIRSCHEIN, 1987 apud HAYKIN, 2001, p. 49).</p>
            <p>Suas duas principais características são "(1) que informação é realmente tornada explícita; e (2) como a informação é codificada fisicamente para o uso subsequente." (HAYKIN, 2001, p. 49). Além disso, deve ser direcionada a um objetivo.</p>
            <p>"Em aplicações do mundo real de máquinas 'inteligentes', podemos dizer que uma boa solução depende de uma boa representação do conhecimento" (WOODS, 1986 apud HAYKIN, 2001, p. 49).</p>
            <p>A rede neural deve ser capaz de aprender a respeito do mundo exterior - isto é, o ambiente no qual está inserida - e constantemente manter essa definição atualizada, de modo a atingir os objetivos específicos da aplicação. Destaca-se que esse conhecimento sobre o mundo consiste, basicamente, em dois tipos de informação:
                <blockquote id="subtitulo_7_nota_20">
                    <ol>
                        <li>O estado conhecido do mundo, representado pelos fatos sobre o que é e o que era conhecido; esta forma de conhecimento é chamada de <em>informação prévia</em>.</li>
                        <li>As observações (medidas) do mundo, obtidas por meio de sensores projetados para sondar o ambiente no qual a rede neural deve operar. Normalmente, estas observações são inerentemente ruidosas, sendo sujeitas a erros devido a ruído<sup><a class="linknotas" href="#nota_20">[20]</a></sup> do sensor e imperfeições do sistema. De qualquer maneira, as observações que são assim obtidas fornecem o conjunto de informações de onde são retirados os <em>exemplos</em> utilizados para treinar a rede neural. (HAYKIN, 2001, p. 50)</li>
                    </ol>
                </blockquote>
            </p>
            <p>Esses exemplos para treinamento podem ser <strong>rotulados ou não rotulados</strong>. No primeiro caso, ao sinal de entrada é associada a resposta esperada, enquanto que, no segundo, não há essa associação e o sinal de entrada é contraposto a ocorrências diferentes dele próprio. Em qualquer caso, <strong>o conjunto de exemplos representa o conhecimento da rede neural sobre o ambiente.</strong></p>
            <p>Também podem ser <strong>positivos ou negativos</strong> isto é, respectivamente voltados a ensinar <strong> o que deve ser reconhecido e o que deve ser ignorado.</strong></p>
            <p>Ao par de dados entrada-saída, respectivamente correspondentes ao sinal de entrada e à resposta desejada, dá-se o nome de <strong>conjunto de dados de treinamento ou amostra de treinamento (<em>set of training data or training sample</em>).</strong></p>
            <p>Nesse sentido, um possível projeto de uma rede neural teria duas fases, quais sejam, a de <strong> aprendizagem (<em>learning</em>)</strong>, na qual haveria a exposição ao conjunto de dados, e a de <strong> generalização (<em>generalization</em>)</strong>, depois da testagem bem-sucedida após o treinamento, que consiste na capacidade de repetir idêntica performance em cenários que envolvam dados que não foram apresentados durante o treinamento.</p>
            <p>Diferentemente do que ocorre nos classificadores de padrões clássicos, "[...] a rede neural não somente fornece o modelo implícito do ambiente no qual ela está inserida, como também realiza a função de processamento de informação de interesse" (HAYKIN, 2001, p. 50).</p>
            <p>A representação do conhecimento perpassa pelo ajuste dos pesos sinápticos e do <em>bias</em>, isto é, dos <strong>parâmetros livres da rede</strong>. "A forma dessa representação de conhecimento constitui o verdadeiro projeto da rede neural, e portanto é a chave para o seu desemprenho" (HAYKIN, 2001, p. 51).</p>

            <h3>7.1 Regras de representação do conhecimento</h3>
            <p>Há quatro regras comumente aceitas (ANDERSON, 1988 apud HAYKIN, 2001, p. 51/53):
                <blockquote>
                    <ol>
                        <li>Entradas similares de classes similares normalmente devem produzir representações similares no interior da rede, e portanto devem ser classificadas como pertencentes à mesma categoria.</li>
                        <li>Devem ser atribuídas representações bem diferentes na rede a itens que devem ser categorizados como classes separadas.</li>
                        <li>Se uma característica particular é importante, então deve haver um grande número de neurônios envolvidos na representação daquele item na rede.</li>
                        <li>Informação prévia e invariâncias devem ser incorporadas no projeto de uma rede neural, simplificando com isso o projeto da rede por não ter que aprendê-las.</li>
                    </ol>
                </blockquote>
            </p>
            <p>"Correlation plays a key role not only in the human brain, but also in signal processing of various kinds" (CHEN ET AL., 2007 apud HAYKIN, 2009, p. 28). Em tradução direta, "a correlação desempenha um papel fundamental não apenas no cérebro humano, mas também no processamento de sinais de vários tipos".</p>
            <p><strong>Probabilidade de detecção vs. probabilidade de falso alarme</strong> - Critério de Neyman-Pearson: "[...] a probabilidade de detecção é maximizada, sujeita à restrição de que a probabilidade de alarme falso não exceda a um determinado valor" (VAN TREES, 1968 apud HAYKIN, 2001, p. 53).</p>
            <p>A regra 4 significa que é <em>altamente desejável</em> que a rede neural possua estrutura especializada (restrita), o que se justifica pelo fato de que há alta especialização em redes biológicas (visuais e auditivas, por exemplo), pela necessidade de menos parâmetros livres e menores conjuntos de dados para treinamento e pela maior eficiência (aumento da produtividade  e redução de custos) (Russo apud Haykin, 2001).</p>
            <p>A utilização de informação prévia restringe a aplicabilidade da rede a um domínio específico (Haykin, 2009).</p>
                
            <h3>7.2 Como incorporar informação prévia no projeto de uma rede neural</h3>
                <p>Duas regras são comumente aceitas, as quais, particularmente a segunda, contribuem significativamente para a diminuição do número de parâmetros livres da rede:
                    <blockquote>
                        <ol>
                            <li>Restringir a arquitetura da rede pelo uso de conexões locais conhecidas como campos receptivos (<em>receptive fields</em>); e</li>
                            <li>Restringir a escolha de pesos sinápticos através do uso de compartilhamento de pesos. (LECUN ET AL., 1990 apud HAYKIN, 2001, p. 54)</li>
                        </ol>
                    </blockquote>
                </p>
                <p>
                    O termo <strong>campo receptivo</strong> diz respeito ao <strong>limiar de excitação</strong> a partir do qual os dados de entrada são capazes de influenciar a saída do neurônio, isto é, à <strong>sensibilidade a estímulos</strong> do neurônio ou da conexão sináptica.
                    Já o compartilhamento de pesos sinápticos é tão somente o que seu próprio nome sugere. Nesse sentido:
                    <blockquote>
                        The receptive field of a neuron is defined as that region of the input field over which the incoming stimuli can influence the output signal produced by the neuron. The mapping of the receptive field is a powerful and shorthand description of the neuron’s behavior, and therefore its output. To satisfy the weight-sharing constraint, we merely have to use the same set of synaptic weights for each one of the neurons in the hidden layer of the network. (HAYKIN, 2009, p. 30)
                    </blockquote>
                </p>
                <p>Uma rede implementada com essas características é denominada <strong>rede convolucional (<em>convolutional network</em>)</strong>.</p>
                <p>A seguir, o grafo arquitetural exemplificativo de uma rede convolucional:
                    <div class="image-container">
                        <figure>
                            <img src="../../../imagens/11_convolutional_network_architectural_graph.png" alt="Grafo arquitetural de uma rede convolucional">
                            <figcaption class="legenda">Figura 11 - Grafo arquitetural de uma rede convolucional. Fonte: HAYKIN, 2009, p. 31.</figcaption>
                        </figure>
                    </div>
                </p>
                <p>Observa-se que a camada de entrada é formada pelo total de dez nós <math><mi>k</mi></math>, cada qual recebendo um único sinal <math><mi>x</mi></math>, que estão conectados de seis em seis a um único neurônio da camada oculta, que é composta por quatro neurônios -- <math><msub><mi>j</mi><mi>1</mi></math> a <math><msub><mi>j</mi><mi>4</mi></math>.</p>
                <p id="subtitulo_7_2_nota_21">
                    Assim, considerando que cada um dos quatro neurônios ocultos tem seis conexões sinápticas e que todos compartilham o mesmo conjunto de pesos sinápticos -- 
                    <math xmlns="http://www.w3.org/1998/Math/MathML">
                        <msup>
                            <mrow>
                                <mo>{</mo>
                                <msub>
                                    <mi>w</mi>
                                    <mi>i</mi>
                                </msub>
                                <mo>}</mo>
                            </mrow>
                            <mn>6</mn>
                        </msup>
                        <sub>i</sub>
                        <mo>=</mo>
                        <mn>1</mn>
                    </math>
                    --, o campo local induzido<sup><a class="linknotas" href="#nota_21">[21]</a></sup> <math><mi>v</mi></math> de qualquer neurônio <math><mi>j</mi></math>, para cada uma das seis conexões sinápticas -- <math><mi>i</mi></math> --, é dado pela equação
                    <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                        <msub>
                            <mi>v</mi>
                            <mi>j</mi>
                        </msub>
                        <mo>=</mo>
                        <munderover>
                            <mo>&#x2211;</mo>
                            <mrow>
                                <mi>i</mi>
                                <mo>=</mo>
                                <mn>1</mn>
                            </mrow>
                            <mrow>
                                <mn>6</mn>
                            </mrow>
                        </munderover>
                        <msub>
                            <mi>w</mi>
                            <mi>i</mi>
                        </msub>
                        <msub>
                            <mi>x</mi>
                            <mi>k</mi>
                        </msub>
                        <mtext>&nbsp; , &nbsp; j = 1, 2, 3, 4</mtext>
                    </math>
                </p>
                <p>Sendo <math><mtext>k = i + j - 1</mtext></math> e, portanto, <math><msub><mi>x</mi><mi>k</mi></msub></math> o próprio sinal de entrada.</p>
                
                <h3>7.3 Invariâncias no projeto de uma rede neural</h3>
                <p>É desejável que o sistema seja invariante perante transformações como a rotação do objeto de interesse, a alterações de amplitude ou frequência de ondas, timbre, entonação ou velocidade de voz, etc.</p>
                <p>"[...] o sistema deve ser capaz de lidar com uma série de transformações do sinal observado" (Barnard; Casasent, 1991, apud HAYKIN, 2001, p. 55).</p>
                <p>"Em outras palavras, uma estimativa de classe representada por uma saída do classificador não deve ser afetada pelas transformações do sinal observado aplicado à entrada do classificador." (HAYKIN, 2001, p. 55).</p>
                <p>Há pelo menos três técnicas para implementar o dito classificador invariante a transformações (Barnard; Casasent, 1991, apud HAYKIN, 2001):
                    <blockquote>
                        <ul>
                            <li><strong>Invariância por estrutura:</strong> as versões transformadas do mesmo sinal de entrada são forçadas a produzir o mesmo sinal de saída, por meio da criação de novas conexões sinápticas, o que resulta na desvantagem de que o número de conexões da rede aumenta demasiadamente.</li>
                            <li><strong>Invariância por treinamento:</strong> durante o treinamento, à rede são apresentadas diversas variações do mesmo objeto, de modo que possa generalizá-lo e reconhecê-lo em suas variadas formas. Como desvantagens, não há certeza de que o comportamento invariante alcançará transformações não vistas ou objetos de outras classes, além da maior demanda por recursos computacionais.</li>
                            <li><strong>Espaço de características invariantes:</strong> envolve a extração das principais características invariantes - isto é, que não se modificam - do objeto apresentado (e/ou seu conteúdo essencial), a fim de que, por generalização, a rede seja capaz de observá-las em outros objetos e, diante disso, classificá-los como da mesma classe. Idealmente, a rede somente precisaria lidar com fatores inevitáveis como ruídos e oclusão. Destacam-se vantagens como a redução do número de características do objeto a níveis realistas, a redução das exigências impostas à rede neural e a certeza de invariância em relação a todas as variações conhecidas do objeto.</li>
                        </ul>
                    </blockquote>
                </p>
                <a class="emoji" href="#top">[ 🔝 ]</a>
        </article>

        <article>
            <h2 id="subtitulo_8">8. Processos de aprendizagem<sup> <a class="linknotas" href="#nota_22">[22]</a></sup></h2>
            
            <h3 id="subtitulo_8_1">8.1 Conceito de aprendizagem</h3>
            <p>
                <blockquote>
                    Aprendizagem é um processo pelo qual os parâmetros livres de uma rede neural são adaptados através de um processo de estimulação pelo ambiente no qual a rede está inserida. O tipo de aprendizagem é determinado pela maneira pela qual a modificação dos parâmetros ocorre. (HAYKIN, 2001, p. 75)
                </blockquote>
            </p>
            <p>É fundamental que a rede neural seja capaz de aprender a partir de seu ambiente e, através de um processo contínuo de ajuste de pesos sinápticos e níveis de <em>bias</em><sup><a class="linknotas" href="#nota_23">[23]</a></sup>, melhorar o seu desempenho, respondendo de maneira diferente àquele mesmo ambiente, em razão das modificações sofridas.</p>
            <p>"Um conjunto preestabelecido de regras bem-definidas para a solução de um problema de aprendizagem é denominado um algoritmo de aprendizagem. [...] Basicamente, os algoritmos de aprendizagem diferem entre si pela forma como é formulado o ajuste de um peso sináptico de um neurônio." (HAYKIN, 2001, p. 76)</p>
            
            <h4>8.1.1 Regras básicas de aprendizagem</h4>
            <h5>8.1.1.1 Aprendizagem por correção</h5>
            <p>
                Consiste no ajuste dos pesos sinápticos do neurônio até que o sistema atinja um denominado <strong>estado estável</strong>, em que os próprios pesos estariam estabilizados de modo a minimizar o erro entre a saída da rede neural e a <strong>resposta desejada ou saída-alvo</strong> -- 
                <math>
                    <mrow>
                        <msub>
                        <mi>d</mi>
                        <mrow>
                            <mi>k</mi>
                        </mrow>
                        </msub>
                    <mo stretchy="false">(</mo>
                    <mi>n</mi>
                    <mo stretchy="false">)</mo>
                  </mrow>
                </math> 
                 --, em que <math><mi>k</mi></math> é um neurônio de camada oculta que foi acionado pelo sinal <math><mi>x</mi><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></math>, proveniente também de camada(s) oculta(s), e "o argumento <math><mi>n</mi></math> representa o instante de tempo discreto, ou mais precisamente, o passo de tempo de um processo iterativo envolvido no ajuste dos pesos sinápticos do neurônio <math><mi>k</mi></math>, tal como ilustrado abaixo:
                <div class="image-container">
                    <figure>
                        <img src="../../../imagens/12_aprendizagem_correcao_de_erro.png" alt="Ilustração da regra da aprendizagem por correção de erros">
                        <figcaption class="legenda">Figura 12 - Ilustração da regra da aprendizagem por correção de erros. Fonte: HAYKIN, 2001, p. 77.</figcaption>
                    </figure>
                </div>
            </p>
            <p>
                O sinal de erro produzido, representado por <math><mrow><msub><mi>e</mi><mrow><mi>k</mi></mrow></msub><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></math>, é a diferença entre a saída desejada e a saída real da rede neural, isto é, <math><mrow><msub><mi>e</mi><mrow><mi>k</mi></mrow></msub><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>d</mi><mrow><mi>k</mi></mrow></msub><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo><mo>-</mo><msub><mi>y</mi><mrow><mi>k</mi></mrow></msub><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></math>. 
                Esse sinal "[...] aciona um mecanismo de controle, cujo propósito é aplicar uma sequência de ajustes corretivos aos pesos sinápticos do neurônio <math><mi>k</mi></math> [...] projetados para aproximar passo a passo o sinal de saída <math><mrow><msub><mi>y</mi><mrow><mi>k</mi></mrow></msub><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></math> da resposta desejada <math><mrow><msub><mi>d</mi><mrow><mi>k</mi></mrow></msub><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></math>. 
                Este objetivo é alcançado minimizando-se uma <strong>função de custo ou índice de desempenho</strong> [...]" (HAYKIN, 2001, p. 77).
            </p>
            <p>
                O índice de desempenho -- <math><mi>E</mi></math> -- é definido em termos de <math><mrow><msub><mi>e</mi><mrow><mi>k</mi></mrow></msub><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></math> como
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
                    <mrow>
                        <mi>E</mi>
                        <mo>=</mo>
                        <mfrac>
                            <mn>1</mn>
                            <mn>2</mn>
                        </mfrac>
                        <msub>
                            <msup>
                                <mi>e</mi>
                                <mn>2</mn>
                            </msup>
                            <mi>k</mi>
                        </msub>
                        <mo stretchy="false">(</mo>
                        <mi>n</mi>
                        <mo stretchy="false">)</mo>
                    </mrow>
                </math>
                e corresponde ao <strong>valor instantâneo da energia do erro.</strong> A minimização dessa função de custo resulta na <strong>regra delta ou regra de Widrow-Hoff</strong>, que pode ser formulada como "o ajuste feito em um peso sináptico de um neurônio é proporcional ao produto do sinal de erro pelo sinal de entrada da sinapse em questão" (HAYKIN, 2001, p. 78) e é dada por:
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>&#x2206; <!-- Delta --> </mi>
                    <msub>
                        <mi>w</mi>
                            <mi>kj</mi>
                    </msub>
                      <mo stretchy="false">(</mo>
                      <mi>n</mi>
                      <mo stretchy="false">)</mo>
                      <mo>=</mo>
                      <mi>&#x03B7; . <!-- Greek small letter eta --></mi>
                      <msub>
                        <mi>&nbsp; e</mi>
                        <mrow>
                          <mi>k</mi>
                        </mrow>
                      </msub>
                      <mo stretchy="false">(</mo>
                      <mi>n</mi>
                      <mo stretchy="false">)</mo>
                      <msub>
                        <mi>x</mi>
                        <mrow>
                          <mi>j</mi>
                        </mrow>
                      </msub>
                      <mo stretchy="false">(</mo>
                      <mi>n</mi>
                      <mo stretchy="false">)</mo>
                    </mrow>
                  </math>            
            </p>
            <p>A <strong>taxa de aprendizagem</strong>, representada pela letra <math><mi>&#x03B7;</mi></math> , é uma constante positiva que aumenta conforme o incremento do passo no processo de aprendizagem. Essa regra exige que o sinal de erro seja diretamente mensurável e que a resposta desejada seja conhecida e fornecida à rede neural por alguma fonte externa com acesso direto ao neurônio <math><mi>k</mi></math>, do que se depreende que esse neurônio necessariamente seja visível ao mundo externo e que o erro é corrigido apenas localmente, isto é, são ajustadas apenas as sinapses do neurônio <math><mi>k</mi></math>, como visto na figura acima.</p>
            <p>
                O ajuste sináptico -- <math><mi>&#x2206;</mi><msub><mi>w</mi><mi>kj</mi></msub><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></math> --, que atualiza o peso sináptico <math><msub><mi>w</mi><mi>kj</mi></msub></math> é determinado pela equação 
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mrow>
                        <mi>&#x2206;</mi>
                        <msub>
                            <mi>w</mi>
                                <mi>kj</mi>
                        </msub>
                      <mo stretchy="false">(</mo>
                      <mrow>
                        <mi>n</mi>
                        <mo>+</mo>
                        <mn>1</mn>
                      </mrow>
                      <mo stretchy="false">)</mo>
                      <mo>=</mo>
                      <msub>
                        <mi>w</mi>
                        <mrow>
                          <mi>kj</mi>
                        </mrow>
                      </msub>
                      <mo stretchy="false">(</mo>
                      <mi>n</mi>
                      <mo stretchy="false">)</mo>
                      <mo>+</mo>
                      <mi>&#x2206;</mi>
                      <msub>
                          <mi>w</mi>
                          <mi>kj</mi>
                      </msub>
                      <mo stretchy="false">(</mo>
                      <mi>n</mi>
                      <mo stretchy="false">)</mo>
                    </mrow>
                  </math>                  
                  
                  ou pela equação
                  
                  <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mrow>
                        <mi>&#x2206;</mi>
                        <msub>
                            <mi>w</mi>
                            <mi>kj</mi>
                        </msub>
                        <mo stretchy="false">(</mo>
                        <mi>n</mi>
                        <mo stretchy="false">)</mo>
                        <mo>=</mo>
                        <msup>
                            <mi>z</mi>
                            <mrow>
                            <mn>-1</mn>
                            </mrow>
                        </msup>
                        <mo stretchy="false">[</mo>
                        <msub>
                            <mi>w</mi>
                            <mi>kj</mi>
                        </msub>
                        <mo stretchy="false">(</mo>
                        <mi>n</mi>
                        <mo stretchy="false">)</mo>
                        <mo>+</mo>
                        <mn>1</mn>
                        <mo stretchy="false">]</mo>
                    </mrow>
                </math>

                em que <math><msup><mi>z</mi><mn>-1</mn></msup></math> é o <strong>operador de atraso unitário, que representa um elemento de armazenamento.</strong>
            </p>
            <p>Na figura (b), acima, o sinal de entrada <math><msub><mi>x</mi><mi>j</mi></msub></math> e o campo local induzido <math><msub><mi>v</mi><mi>k</mi></msub></math> correspondem, respectivamente, aos sinais pré e pós-sináptico da <math><mi>j</mi></math>-ésima sinapse do neurônio <math><mi>k</mi></math>.</p>
            
            <h5>8.1.1.2 Aprendizagem baseada em memória</h5>
            <p>
                O conhecimento (experiência), em sua totalidade ou maioria, é explicitamente armazenado e classificado no formato de pares de exemplos de entrada-saída -- 
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
                    <msub>
                        <msup>
                            <mrow>
                                <mo fence="true" stretchy="true">{</mo>
                                <msub>
                                    <mi>x</mi>
                                    <mi>i</mi>
                                </msub>
                                <mo>,</mo>
                                <msub>
                                    <mi>d</mi>
                                    <mi>i</mi>
                                </msub>
                                <mo fence="true" stretchy="true">}</mo>
                            </mrow>
                            <mi>N</mi>
                        </msup>
                        <mrow>
                            <mi>i</mi>
                            <mo>=</mo>
                            <mn>1</mn>
                        </mrow>
                    </msub>
                        <msup>
                        </msup>
                </math>                  
                --, sendo <math><msub><mi>x</mi><mi>i</mi></msub></math> e <math><msub><mi>d</mi><mi>i</mi></msub></math> o sinal de entrada e a resposta desejada, respectivamente.
            </p>
            <p>Um dos algoritmos que utiliza esta regra é o do <strong>vizinho mais próximo (regra do vizinho mais próximo ou <em>nearest neighbor algorithm</em>).</strong></p>

            <h5>8.1.1.3 Aprendizagem Hebbiana</h5>
            <p>O <strong>postulado de aprendizado de Hebb</strong>, em homenagem ao neuropsicólogo Donald Hebb, autor do livro <em>The Organization of Behavior</em> (1949), preconiza que "quando um axônio da célula A está perto o suficiente para excitar uma célula B e participa do seu disparo repetida ou persistentemente, então algum processo de crescimento ou modificação metabólica acontece em uma das células ou em ambas, de tal forma que a eficiência de A como uma das células que dispara B é aumentada." (HEBB, 1949 apud HAYKIN, 2001, p. 80). Essa modificação seria embasada na aprendizagem associativa a nível celular, culminando na modificação permanente do padrão de atividade das células envolvidas.</p>
            <p>
                Esse postulado pode ser dividido em duas partes, no que se denomina <strong>sinapse hebbiana</strong>, embora originalmente Hebb não tenha proposto a segunda (Stent, 1973; Changeux, Danchin, 1976 apud HAYKIN, 2001, p. 80):
                <blockquote>
                    <ol>
                        <li>Se dois neurônios em ambos os lados de uma sinapse (conexão) são ativados simultaneamente [...], então a força daquela sinapse é seletivamente aumentada.</li>
                        <li>Se dois neurônios em ambos os lados de uma sinapse são ativados assincronamente, então aquela sinapse é seletivamente enfraquecida ou eliminada.</li>
                    </ol>
                </blockquote>
            </p>
            <p>A <strong>sinapse hebbiana</strong> pode ser definida como "[...] uma sinapse que usa um mecanismo dependente do tempo, altamente local e fortemente interativo para aumentar a eficiência sináptica como uma função da correlação entre as atividades pré-sináptica e pós-sináptica." (HAYKIN, 2001, p. 80/81).</p>
            <p>
                Quatro <strong>mecanismos/propriedades fundamentais</strong> dessa espécie de sinapse (Brown et al., 1990 apud Haykin, 2001):
                <ol>
                    <li><strong>Dependente do tempo</strong> de ocorrência dos sinais pré e pós-sinápticos;</li>
                    <li><strong>Local</strong>, referindo-se ao fato de que a sinapse é um local contíguo no espaço-tempo onde ocorre a transmissão dos sinais portadores de informação;</li>
                    <li><strong>Interativo</strong>, pois a modificação proposta em uma sinapse hebbiana é dependente da atividade de ambos os lados da sinapse; e</li>
                    <li><strong>Conjuncional ou correlativo</strong>, no sentido de que a mera "[...] ocorrência simultânea dos sinais pré-sináptico e pós-sináptico (dentro de um curto intervalo de tempo) é suficiente para produzir a modificação sináptica." (HAYKIN, 2001, p. 81), isso porque "a correlação é de fato a base do aprendizado" (Eggermont, 1990 apud HAYKIN, 2001, p. 81).</li>
                </ol>
            </p>

            <h6>8.1.1.3.1 Reforço e depressão sinápticos</h6>
            <p>
                A modificação sináptica pode ser desencadeada por uma atividade positivamente correlacionada, a qual reforça aquela sinapse, ou por uma atividade não-correlacionada ou negativamente correlacionada, que enfraquece a sinapse (Stent, 1973, apud Haykin, 2001). 
                Ela [a modificação sináptica] pode também ser classificada como hebbiana, anti-hebbiana e não-hebbiana (Palm, 1982 apud Haykin, 2001), respectivamente descritas como a que aumenta ou diminui a força conforme há correlação positiva ou negativa entre os sinais pré e pós-sinápticos, a que, inversamente, aumenta se houver correlação negativa e diminui se houver correlação positiva, e a que não é afetada pela correlação entre os sinais pré e pós-sinápticos (não envolve qualquer mecanismo hebbiano).
            </p>

            <h6>8.1.1.3.2 Modelos matemáticos de modificações hebbianas</h6>
            <p>
                Em termos matemáticos, a formulação da aprendizagem hebbiana é dada por uma função <math><mi>F</mi></math> que depende tanto do sinal pré-sináptico 
                <math><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="true">(</mo><mi>n</mi><mo stretchy="true">)</mo></math> quanto do sinal pós-sináptico <math><msub><mi>y</mi><mi>k</mi></msub><mo stretchy="true">(</mo><mi>n</mi><mo stretchy="true">)</mo></math>, isto é, <math><mi>F</mi><mo stretchy="true">(</mo><msub><mi>x</mi><mi>j</mi></msub><mo stretchy="true">(</mo><mi>n</mi><mo stretchy="true">), </mo><msub><mi>y</mi><mi>k</mi></msub><mo stretchy="true">(</mo><mi>n</mi><mo stretchy="true">)</mo><mo>)</mo></math>, conforme a equação abaixo:                
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mrow>
                        <mi>&#x2206;</mi>
                        <msub>
                            <mi>w</mi>
                            <mrow>
                                <mi>kj</mi>
                            </mrow>
                        </msub>
                        <mo stretchy="false">(</mo>
                        <mi>n</mi>
                        <mo stretchy="false">)</mo>
                        <mo>=</mo>
                        <mi>F</mi>
                        <mo stretchy="false">(</mo>
                        <msub>
                            <mi>y</mi>
                            <mrow>
                            <mi>k</mi>
                            </mrow>
                        </msub>
                        <mo stretchy="false">(</mo>
                        <mi>n</mi>
                        <mo stretchy="false">)</mo>
                        <mo>,</mo>
                        <msub>
                            <mi>x</mi>
                            <mrow>
                            <mi>j</mi>
                          </mrow>
                        </msub>
                        <mo stretchy="false">(</mo>
                        <mi>n</mi>
                        <mo stretchy="false">)</mo>
                        <mo stretchy="false">)</mo>
                        </mrow>
                    </math>
            </p>
            <p>Ou, alternativamente, pelas equações da <strong>hipótese de Hebb</strong> ou da <strong>hipótese da covariância</strong>, esta que foi introduzida por Sejnowski (1977).</p>
            <p>A primeira, logo abaixo, envolve a constante positiva <math><mi>&#x03B7;</mi></math>, que é a taxa de aprendizagem, e pode ser referida como regra do produto das atividades. Nela, há um crescimento exponencial do sinal/atividade pós-sináptica <math><msub><mi>y</mi><mi>k</mi></msub></math>, que conduz a um "[...] ponto [em que] nenhuma informação será armazenada na sinapse e a seletividade é perdida" (HAYKIN, 2001, p. 82), ou seja, à saturação da conexão sináptica. Abaixo a equação:</p>
            <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                <mrow>
                    <mi>&#x2206;</mi>
                    <msub>
                        <mi>w</mi>
                        <mrow>
                            <mi>kj</mi>
                        </mrow>
                    </msub>
                    <mo stretchy="false">(</mo>
                    <mi>n</mi>
                    <mo stretchy="false">)</mo>
                    <mo>=</mo>
                    <mi>&#x03B7;</mi>
                    <msub>
                        <mi>y</mi>
                        <mrow>
                            <mi>k</mi>
                        </mrow>
                    </msub>
                    <mo stretchy="false">(</mo>
                    <mi>n</mi>
                    <mo stretchy="false">)</mo>
                    <msub>
                        <mi>x</mi>
                        <mrow>
                            <mi>j</mi>
                        </mrow>
                    </msub>
                    <mo stretchy="false">(</mo>
                    <mi>n</mi>
                    <mo stretchy="false">)</mo>
                </mrow>
            </math>
            <p>
                Na segunda, por sua vez, os sinais pré e pós-sinápticos são substituídos pelos respectivos desvios em relação aos igualmente respectivos valores médios (
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
                    <mover>
                      <mi>x</mi>
                      <mo>&#xAF;<!-- macron --></mo>
                    </mover>
                </math>
                e 
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline">
                    <mover>
                      <mi>y</mi>
                      <mo>&#xAF;<!-- macron --></mo>
                    </mover>
                  </math>
                ) num dado intervalo temporal, sendo que os valores médios constituem os limiares que determinam o sinal da modificação sináptica. Ela é dada pela equação
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mrow>
                        <mi>&#x2206;</mi>
                      <msub>
                          <mi>w</mi>
                        <mrow>
                          <mi>kj</mi>
                        </mrow>
                      </msub>
                      <mo stretchy="false">(</mo>
                      <mi>n</mi>
                      <mo stretchy="false">)</mo>
                      <mo>=</mo>
                      <mi>&#x03B7; <!-- Greek small letter eta --></mi>
                      <mo stretchy="false">(</mo>
                      <msub>
                          <mi>x</mi>
                          <mi>j</mi>
                      </msub>
                      <mo>&#x2212;<!-- minus sign --></mo>
                      <mover>
                        <mi>x</mi>
                        <mo>&#xAF;<!-- macron --></mo>
                      </mover>
                      <mo stretchy="false">)</mo>
                      <mo stretchy="false">(</mo>
                      <msub>
                        <mi>y</mi>
                        <mi>k</mi>
                      </msub>
                      <mo>&#x2212;<!-- minus sign --></mo>
                      <mover>
                        <mi>y</mi>
                        <mo>&#xAF;<!-- macron --></mo>
                      </mover>
                      <mo stretchy="false">)</mo>
                    </mrow>
                </math>                  
            </p>
            <p>
                A <strong>hipótese da covariância</strong> permite a convergência para um estado não trivial, de equilíbrio, quando <math display="inline"><msub><mi>x</mi><mi>k</mi></msub><mo>=</mo><mover><mi>x</mi><mo>&#xAF;</mo></mover></math> ou <math display="inline"><msub><mi>y</mi><mi>j</mi></msub><mo>=</mo><mover><mi>y</mi><mo>&#xAF;</mo></mover></math>, e prever a potenciação ou a depressão sináptica. O reforço do peso sináptico <math><msub><mi>w</mi><mi>kj</mi></msub></math> ocorre se <math display="inline"><msub><mi>x</mi><mi>j</mi></msub><mo>></mo><mover><mi>x</mi><mo>&#xAF;</mo></mover></math> e <math display="inline"><msub><mi>y</mi><mi>k</mi></msub><mo>></mo><mover><mi>y</mi><mo>&#xAF;</mo></mover></math>, enquanto que a depressão ocorre se houver ativação pré-sináptica na ausência de ativação pós-sináptica suficiente ou vice-versa.
            </p>
            <p>A figura abaixo ilustra graficamente as duas hipóteses:
                <div class="image-container">
                    <figure>
                        <img src="../../../imagens/13_grafico_hipoteses_hebb_e_covariancia.png" alt="Ilustração das hipóteses de Hebb e da covariância">
                        <figcaption class="legenda">Figura 13 - Ilustração das hipóteses de Hebb e da covariância. Fonte: HAYKIN, 2001, p. 82.</figcaption>
                    </figure>
                </div>
            </p>

            <h5>8.1.1.4 Aprendizagem competitiva</h5>
            <p>Ocorreria uma competição entre os neurônios da camada de saída da rede neural para que se tornassem ativos -- isto é, disparassem --, isso porque, diferentemente do que ocorre no modelo baseado na aprendizagem hebbiana, "[...] na aprendizagem competitiva somente um único neurônio de saída está ativo em um determinado instante" (HAYKIN, 2001, p. 83), o que a torna adequada para "[...] descobrir características estatisticamente salientes que podem ser utilizadas para classificar um conjunto de padrões de entrada." (HAYKIN, 2001, p. 83).</p>
            <p>
                Três elementos básicos (Rumelhart; Zisper, 1985):
                <ul>
                    <li>Neurônios com pesos sinápticos diferentes são aleatoriamente distribuídos para que respondam diferentemente ao padrão de entrada;</li>
                    <li>A "força" de cada neurônio é limitada; e</li>
                    <li>Existência de um mecanismo que possibilite a competição entre os neurônios ("neurônio vencedor leva tudo" (HAYKIN, 2001, p. 84)).</li>
                </ul>
            </p>
            <p>Essa abordagem favorece a especialização e o agrupamento de neurônios da rede para o reconhecimento de padrões específicos, que se tornam detectores de características dos padrões de entrada (Haykin, 2001). Cada neurônio <math><mi>k</mi></math> da rede possuiria um montante fixo de peso sináptico para que fosse distribuído entre seus nós de entrada
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <munder>
                        <mo>&#x2211;</mo>
                        <mi>j</mi>
                    </munder>
                    <msub>
                        <mi>w</mi>
                        <mi>kj</mi>
                    </msub>
                    <mo>=</mo>
                    <mn>1</mn>
                    <mo>,</mo>
                    <mrow>
                        <mo mathsize="80%">&#x2200;<!-- for all --></mo>
                        <mi>&nbsp;k</mi>
                    </mrow>
                </math>
            </p>
            <p>
                O neurônio cujo campo local induzido -- <math><msub><mi>v</mi><mi>k</mi></msub></math> -- tivesse o maior valor seria o vencedor e, portanto, o único a disparar. Nesse caso, seu sinal de saída -- <math><msub><mi>y</mi><mi>k</mi></msub></math> -- é definido em <math><mn>1</mn></math>, enquanto que o de todos os demais são definidos em <math><mn>0</mn></math>:
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <msub>
                        <mi>y</mi>
                        <mi>k</mi>
                    </msub>
                    <mo>=</mo>
                    <mrow>
                        <mo>{</mo>
                        <mtable>
                          <mtr>
                            <mtd>
                              <mn>1</mn>
                            </mtd>
                            <mtd>
                                <mtext> se &nbsp;</mtext>
                                <msub>
                                    <mi>v</mi>
                                    <mi>k</mi>
                                </msub>
                                <mo>&gt;</mo>
                                <msub>
                                    <mi>v</mi>
                                    <mi>j</mi>
                                </msub>
                                <mspace width="0.5em"/>
                                <mo>&forall;</mo>
                                <mspace width="0.5em"/>
                              <mi>j</mi>
                              <mo>,</mo>
                              <mspace width="0.5em"/>
                              <mi>j</mi>
                              <mo>&ne;</mo>
                              <mi>k</mi>
                            </mtd>
                          </mtr>
                          <mtr>
                            <mtd>
                              <mn>0</mn>
                            </mtd>
                            <mtd>
                              <mtext>caso contrário</mtext>
                            </mtd>
                          </mtr>
                        </mtable>
                    <mrow>
                </math>
            </p>
            <p>
                <blockquote>
                    Um neurônio, então, aprende ao deslocar pesos sinápticos de seus nós de entrada inativos para os seus nós ativos. Se um neurônio não responde a um padrão de entrada particular, então não ocorrerá aprendizado naquele neurônio. Se um neurônio particular vencer a competição, então cada nó de entrada deste neurônio libera uma certa proporção de seu peso sináptico e este peso liberado será então distribuído uniformemente entre os nós de entrada ativos." (HAYKIN, 2001, p. 84)
                </blockquote>
            </p>
            <p>
                Desse modo, a variação do peso sináptico -- <math><mi>&#x2206;</mi><msub><mi>w</mi><mi>kj</mi></msub></math> -- corresponde a
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mrow>
                        <mi>&#x2206;</mi>
                      <msub>
                          <mi>w</mi>
                          <mi>kj</mi>
                      </msub>
                      <mo>=</mo>
                      <mrow>
                        <mo>{</mo>
                        <mtable>
                          <mtr>
                            <mtd>
                              <mi>&#x03B7;</mi>
                                <mo>(</mo>
                                <msub>
                                    <mi>x</mi>
                                    <mi>j</mi>
                                </msub>
                                <mo>-</mo>
                                <msub>
                                    <mi>w</mi>
                                    <mi>kj</mi>
                                </msub>
                                <mo>)</mo>
                            </mtd>
                            <mtd>
                                <mtext> se &nbsp;</mtext>
                                <mi>k</mi>
                                <mspace width="0.5em"/>
                                <mtext> é o neurônio vencedor</mtext>
                            </mtd>
                          </mtr>
                          <mtr>
                            <mtd>
                              <mn>0</mn>
                            </mtd>
                            <mtd>
                              <mtext>caso contrário</mtext>
                            </mtd>
                          </mtr>
                        </mtable>
                </math>
            </p>

            <h5>8.1.1.5 Aprendizagem de Botzmann</h5>
            <p>Trata-se de um algoritmo estocástico (probabilístico) derivado da mecânica estatística. A rede neural projetada com base nessa regra é denominada <strong>máquina de Boltzmann</strong> Analogicamente, busca-se um "equilíbrio térmico" do sistema.</p>
            <p>Os neurônios operam de modo binário e recorrente, variando entre os estados "ligado" (+1) e "desligado" (-1). "A máquina é caracterizada por uma <em>função de energia</em>, <math><mi>E</mi></math>, cujo valor é determinado pelos estados particulares ocupados pelos neurônios individuais da máquina [...]" (HAYKIN, 2001, p. 86). Nesse modelo, não há realimentação.</p>
            <p>
                Sendo <math><msub><mi>x</mi><mi>j</mi></msub></math> o estado atual e <math><msub><mi>w</mi><mi>kj</mi></msub></math> o peso sináptico entre os neurônios <math><mi>k</mi></math> e <math><mi>j</mi></math>, a função de energia é dada por
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>E</mi>
                    <mo>=</mo>
                    <mo>&#x2212;<!-- minus sign --></mo>
                    <mrow>
                        <mfrac>
                            <mn>1</mn>
                            <mn>2</mn>
                        </mfrac>
                    </mrow>
                    <mrow>
                        <munder>
                            <mrow>
                                <munder>
                                    <mo>&#x2211;</mo>
                                    <mi>j</mi>
                                </munder>
                                <munder>
                                    <mo>&#x2211;</mo>
                                    <mi>k</mi>
                                </munder>
                            </mrow>
                            <msub>
                                <mi>x</mi>
                                <mo>&ne;</mo>
                                <mi>j</mi>
                            </msub>
                        </munder>
                        <msub>
                            <mi>w</mi>
                            <mi>kj</mi>
                        </msub>
                        <msub>
                            <mi>x</mi>
                            <mi>k</mi>
                        </msub>
                        <msub>
                            <mi>x</mi>
                            <mi>j</mi>
                        </msub>
                    </mrow>
                </math>
            </p>
            <p id="subtitulo_8_1_1_5_nota_24">
                Um neurônio é aleatoriamente selecionado e tem seu estado invertido, sendo que a probabilidade de que isso ocorra é dada por
                <math xmlns="http://www.w3.org/1998/Math/MathML" display="block">
                    <mi>P</mi>
                    <mo stretchy="false">(</mo>
                    <msub>
                        <mi>x</mi>
                        <mi>j</mi>
                    </msub>
                    <mo>&#x2192;</mo>
                    <mo>&#x2212;<!-- minus sign --></mo>
                    <msub>
                        <mi>x</mi>
                        <mi>j</mi>
                    </msub>
                    <mo stretchy="false">)</mo>
                    <mo>=</mo>
                    <mrow>
                        <mfrac>
                            <mn>1</mn>
                            <mrow>
                                <mn>1</mn>
                                <mo>+</mo>
                                <msup>
                                    <mi>e</mi>
                                    <mrow>
                                        <mo>&#x2212;<!-- minus sign --></mo>
                                        <mrow>
                                            <mfrac>
                                                <mrow>
                                                    <mi>&#x2206;</mi>
                                                    <msub>
                                                        <mi>E</mi>
                                                        <mi>k</mi>
                                                    </msub>
                                                </mrow>
                                                <mi>T</mi>
                                            </mfrac>
                                        </mrow>
                                    </mrow>
                                </msup>
                            </mrow>
                        </mfrac>
                    </mrow>
                </math>
                em que <math><mi>&#x2206</mi><msub><mi>E</mi><mi>k</mi></msub></math> é a variação da energia em razão da troca e <math><mi>T</mi></math> é a pseudotemperatura<sup><a class="linknotas" href="#nota_24">[24]</a></sup>.
            </p>
            <p>Seus neurônios podem ser <strong>visíveis ou ocultos</strong>, funcionando aqueles como uma interface entre a rede e o ambiente (condição presa) e estes livremente (condição de operação livre).</p>

            <h3>8.1.2 O problema da atribuição de crédito</h3>
            <p>
                <blockquote>
                    Basicamente, o problema da atribuição de crédito é o problema de se atribuir crédito ou culpa por resultados globais a cada uma das decisões internas que tenham sido tomadas por uma máquina de aprendizagem e que tenham contribuído para aqueles resultados. 
                    [...] é também denominado <em>problema de carga</em>, isto é, o problema de "carregar" um determinado conjunto de dados de treinamento para dentro dos parâmetros livres da rede. (HAYKIN, 2001, p. 87)
                </blockquote>
            </p>
            <p>A problematização decorre do fato de que "[...] as decisões internas afetam a escolha das ações particulares que são tomadas e, com isso, as ações e não as decisões internas influenciam diretamente os resultados globais." (HAYKIN, 2001, p. 87)</p>
            <p>
                Dois componentes deste problema:
                <ul>
                    <li><strong>Atribuição de crédito por resultados das ações (problema de atribuição de crédito temporal)</strong>, que se preocupa com o <strong>momento (instante temporal)</strong>, isto é, <strong>quando</strong> as ações que merecem crédito foram tomadas; e</li>
                    <li><strong>Atribuição de crédito por ações a decisões internas (problema de atribuição de crédito estrutural</strong>, que se refere a apontar as <strong>estruturas internas</strong> responsáveis pelas ações que sejam merecedoras de crédito.</li>
                </ul>
            </p>
            <p>
                Nesse sentido, 
                <blockquote>
                    o problema de atribuição de crédito estrutural é relevante no contexto de uma máquina de aprendizagem com múltiplos componentes quando devemos determinar precisamente qual componente particular do sistema deve ter seu comportamento alterado e em que medida, de forma a melhorar o desempenho global do sistema. 
                    Por outro lado, o problema de atribuição de crédito temporal é relevante quando há muitas ações tomadas por uma máquina de aprendizagem que acarretam certos resultados, e devemos determinar quais dessas ações foram responsáveis pelos resultados. 
                    O problema combinado de atribuição de crédito temporal e estrutural é enfrentado por qualquer máquina de aprendizagem distribuída que se esforce em melhorar sem desempenho em situações envolvendo comportamento estendido no tempo (Williams, 1988). (HAYKIN, 2001, p. 87)
                </blockquote>
            </p>
        </article>

        <a class="emoji" href="#top">[ 🔝 ]</a>

        <!-- <article>
            <h3 id="subtitulo_8_2">8.2 Paradigmas de aprendizagem</h3>
            <h2 id="subtitulo_9">9. Tipos de aprendizagem</h2>
        </article> -->

        <hr>

        <article>
            <h2>Principais conceitos/definições/ideias extraídos do texto original</h2>
                <ul>
                    <li><p><strong>Definição de rede neural</strong></p>
                        <ul>
                            <li>O cérebro é um sistema de processamento de informações complexo, não linear e paralelo, com capacidade computacional muito superior à dos computadores digitais convencionais.</li>
                            <li>As redes neurais artificiais são inspiradas no cérebro humano e a ele se assemelham na medida em que compostas por neurônios artificiais interconectados.</li>
                            <li>A plasticidade é uma característica importante tanto no cérebro quanto nas redes neurais artificiais e é ela que assegura a adaptação do indivíduo ao ambiente e a capacidade de aprender.</li>
                            <li>Em redes biológicas ou artificiais, os neurônios são a unidade de processamento de informação e, portanto, responsáveis pelo trabalho computacional.</li>
                            <li>Uma rede neural artificial modela o modo como o cérebro biológico realiza determinada tarefa ou função.</li>
                            <li>O processo de aprendizagem tradicional consiste na modificação dos pesos sinápticos da rede neural artificial.</li>
                        </ul>

                        <li><p><strong>Benefícios das redes neurais</strong></p>
                            <ul>
                                <li>Massiva e paralelamente distribuída.</li>
                                <li>Habilidade de aprender e generalizar.</li>
                                <li>Produz saídas (<em>outputs</em>) adequadas para as entradas (<em>inputs</em>) fornecidas.</li>
                                <li>Principais características:
                                    <ul>
                                        <li>Não linearidade (embora individualmente os neurônios artificiais possam ser lineares ou não lineares);</li>
                                        <li>Mapeamento de entrada e saída (na aprendizagem supervisionada);</li>
                                        <li>Adaptabilidade (capacidade de modificar os pesos sinápticos);</li>
                                        <li>Resposta a evidências (não apenas classificar o padrão adequadamente, mas informar o nível de confiabilidade da escolha, rejeitando ambiguidade);</li>
                                        <li>Informação contextualizada (“O conhecimento é representado pela própria estrutura e estado de ativação de uma rede neural.” (HAYKIN, 2001, p. 30));</li>
                                        <li>Tolerância a falhas (devido à sua estrutura massiva e paralelamente distribuída);</li>
                                        <li>Implementação em VSLI (<em>very-large-scale-integration</em>) [6];</li>
                                        <li>Uniformidade de análise e projeto (&quot;[…] as redes neurais desfrutam de universalidade como processadores de informação&quot; (HAYKIN, 2001, p. 30));</li>
                                        <li>Analogia neurobiológica (motivadas por estruturas biológicas do cérebro humano).</li>
                                    </ul>
                                </li>
                            </ul>
                        </li>
                    
                    <li><p><strong>O cérebro humano</strong></p>
                        <ul>
                            <li>Uma das formas de se enxergar o sistema nervoso do ser humano é como um sistema de três estágios composto por cérebro, receptores e atuadores. Os sinais de entrada (<em>input</em>) desse sistema são os estímulos externos e/ou internos que são captados pelos receptores e, submetidos ao dito sistema, tem-se como saída (<em>output</em>) alguma resposta que pode variar desde a mera percepção a um movimento corporal.</li>
                            <li>Os neurônios, estruturas fundamentais do cérebro humano, comunicam-se entre si por meio do processo denominado transmissão sináptica. A sinapse é o local onde essa comunicação ocorre e pode ser, basicamente, elétrica ou química.
                                <ul>
                                    <li>O surgimento de novas conexões entre os neurônios ou a modificação das já existentes são os mecanismos responsáveis pela plasticidade cerebral e, consequentemente, pela aprendizagem.</li>
                                    <li>O potencial de ação (<em>spike</em> ou impulso) é a saída (<em>output</em>) do processamento neuronal.</li>
                                </ul>
                            </li>
                            <li>Anatomicamente, o cérebro se organiza em níveis hierárquicos.</li>
                            <li>Regiões específicas do cérebro são responsáveis por determinadas funções, mas não necessariamente de forma isolada, pois há casos em que um único resultado decorre da ativação de mais de uma região cerebral, que interagem entre si para produzi-lo.
                                <ul>
                                    <li>Isso ocorre porque o cérebro é vastamente interconectado.</li>
                                </ul>
                            </li>
                        </ul>
                    </li>

                    <li><p><strong>Modelos de neurônio</strong></p>
                        <ul>
                            <li>Elementos básicos: um conjunto de sinapses ou elos de ligação (<em>synapses or connecting links</em>), cada um com seu próprio peso ou força; um somador (<em>adder</em>); e uma função de ativação (<em>activation function</em>). Pode ser aplicado outro elemento chamado viés (<em>bias</em>), igualmente relativo a cada neurônio.
                                <ul>
                                    <li>Cada neurônio pode ter seu próprio <em>bias</em>.</li>
                                    <li>Cada neurônio tem o seu campo local induzido (<em>induced local field</em>) ou potencial de ativação (<em>activation potential</em>), que é correlacionado com a saída do combinador linear e o <em>bias</em>.</li>
                                </ul>
                            </li>

                            <li><strong>Tipos de função de ativação</strong>
                                <ul>
                                    <li>Função de limiar ou limite (<em>threshold function</em>)
                                        <ul>
                                        <li>Modelo de McCulloch-Pitts</li>
                                        <li>Determinístico</li>
                                        </ul>
                                    </li>
                                    <li>Função sigmoide
                                        <ul>
                                            <li>Mais utilizada na construção de redes neurais.</li>
                                        </ul>
                                    </li>
                                </ul>
                            </li>

                            <li><strong>Modelo estocástico de neurônio</strong>
                                <ul>
                                    <li>Probabilístico</li>
                                </ul>
                            </li>
                            <li><strong>Representações gráficas de uma rede neural</strong>
                                <ul>
                                    <li>Diagrama em blocos</li>
                                    <li>Grafo de fluxo de sinal</li>
                                    <li>Grafo arquitetural</li>
                                </ul>
                            </li>
                        </ul>
                    </li>

                    <li><p><strong>Feedback</strong></p>
                        <ul>
                            <li>Comum no sistema nervoso dos seres vivos.</li>
                            <li>Importante nas redes neurais recorrentes, embora a não linearidade das unidades de processamento prejudique sua aplicação.</li>
                            <li>O comportamento dinâmico da rede é controlado pelo ajuste dos pesos sinápticos.</li>
                        </ul>
                    </li>

                    <li><p><strong>Arquiteturas de redes neurais</strong></p>
                        <ul>
                            <li>Agrupamento em três grandes categorias:</li>
                                <ol>
                                    <li>Single-Layer Feed-forward Networks</li>
                                    <li>Multilayer Feed-forward Networks</li>
                                    <li>Recurrent Networks</li>
                                </ol>
                        </ul>
                    </li>

                    <li><p><strong>Representação do conhecimento</strong></p></li>
                        <ul>
                            <li>Características:</li>
                                <ul>
                                    <li>Qual informação é tornada explícita</li>
                                    <li>Como a informação é codificada fisicamente para o uso subsequente</li>
                                </ul>
                            <li>Dois tipos essenciais de informação:</li>
                                <ul>
                                    <li>Estado conhecido do mundo (ambiente)</li>
                                    <ul><li>Informação prévia</li></ul>
                                    <li>Observações (medidas) do mundo (ambiente)</li>
                                </ul>
                            <li>Conjunto de dados ou amostra de treinamento (<em>set of training data or training sample</em>)</li>
                                <ul>
                                    <li>Rotulados ou não rotulados</li>
                                    <li>Positivos ou negativos</li>
                                </ul>
                            <li>Objetivos do treinamento:</li>
                                <ul>
                                    <li>Aprendizagem</li>
                                    <li>Generalização</li>
                                </ul>
                            <li><strong>Regras de representação do conhecimento</strong></li>
                                <ul>
                                    <li>Entradas similares de devem produzir representações similares e serem classificadas sob a mesma categoria</li>
                                    <li>Representações diferentes devem pertencer a categorias diferentes</li>
                                    <li>Para características importantes, deve ser designado um grande número de neurônios</li>
                                    <li>Informações prévias e invariâncias devem ser incorporadas sempre que possível</li>
                                    <li><p><strong>Incorporação de informação prévia</strong></p></li>
                                        <ul>
                                            <li>Restringir a arquitetura da rede (campos receptivos)</li>
                                            <li>Restringir a escolha de pesos sinápticos (compartilhamento de pesos)</li>
                                        </ul>
                                    <li><p><strong>Incorporação de invariâncias</strong></p></li>
                                        <ul><li>A rede deve ser invariante a variações do mesmo sinal de entrada, isto é, o sinal de saída não deve ser afetado por meras transformações do sinal de entrada</li></ul>
                                </ul>
                        </ul>

                        <li><p><strong>Processos de aprendizagem</strong></p></li>
                        <ul>
                            <li>
                                 <strong>Conceito: </strong>consiste no ajuste dos parâmetros livres (peso sináptico e *bias*) da rede neural em resposta aos estímulos recebidos do ambiente (dados de entrada).
                            </li>
                            <li><strong>Regras básicas comuns</strong></li>
                                <ul>
                                    <li>
                                        <strong>Aprendizagem por correção de erros: </strong>os pesos sinápticos são ajustados até que o sistema atinja um estado estável, de modo a minimizar o erro entre a saída da rede neural e a resposta desejada. É gerado um sinal de erro, que corresponde à diferença entre a saída desejada e a obtida e funciona como um mecanismo de controle.
                                    </li>
                                    <li>
                                        <strong>Aprendizagem baseada em memória: </strong>o conhecimento (dados de treinamento) é explícita e individualmente armazenado e classificado no formato de pares de entrada-saída, consultando-os diretamente em busca de características específicas que levaram àquela classificação. Os próprios exemplos são memorizados.
                                    </li>
                                    <li>
                                        <strong>Aprendizagem Hebbiana: </strong>baseia-se no postulado de aprendizado de Hebb, que preconiza que a eficiência sináptica é aumentada conforme dois neurônios (pré e pós-sinápticos) são ativados simultaneamente. Diferentemente da proposição original, admite-se o enfraquecimento ou eliminação da sinapse se a ativação de dois neurônios ocorrer assincronamente, isto é, não correlacionadamente.
                                    </li>
                                    <li>
                                        <strong>Aprendizagem competitiva: </strong>os neurônios da camada de saída competem entre si, pois apenas um deles será ativado. Favorece a especialização e o agrupamento de neurônios da rede para o reconhecimento de padrões específicos (detectores de características estatisticamente relevantes dos padrões de entrada).
                                    </li>
                                    <li>
                                        <strong>Aprendizagem de Boltzmann: </strong>modelo estocástico no qual os neurônios formam uma rede recorrente e binária, em busca do "equilíbrio térmico" do sistema. Um parâmetro de controle denominado pseudotemperatura é utilizado para determinar a probabilidade de que um neurônio seja selecionado e tenha seu estado invertido.
                                    </li>
                                </ul>
                            <li>
                                <strong>O problema da atribuição de crédito: </strong>cuida da dificuldade de se atribuir o crédito ou a culpa individualmente a elementos ou partes internas de um sistema complexo, como é o caso de uma rede neural, com o objetivo de compreender qual foi a contribuição de cada um deles para o resultado global do sistema.
                            </li>
                        </ul>
                </ul>
            <a class="emoji" href="#top">[ 🔝 ]</a>
        </article>

        <hr>
        
        <article>
            <h2>Referências complementares consultadas durante o fichamento deste capítulo</h2>
            <p>AGUIAR, Marcus A. M. **Sistemas dinâmicos**. Universidade Estadual de Campinas. 2005. Disponível em <a href="https://sites.ifi.unicamp.br/aguiar/files/2014/10/sistemas-dinamicos.pdf" target="_blank">https://sites.ifi.unicamp.br/aguiar/files/2014/10/sistemas-dinamicos.pdf</a>. Acesso em 02 fev. 2024.</p>
            <p>BEAR, Mark F.; CONNORS, Barry W.; PARADISO, Michael A. <strong>Neurociências: desvendando o sistema nervoso</strong>. Trad. Carla Dalmaz et al. 4. ed. Porto Alegre: Artmed, 2017.</p>
            <p>GALLINARO, Júlia V.; SCHOLL, Benjamin; CLOPATH, Claudia. 2023. <strong>Synaptic weights that correlate with presynaptic selectivity increase decoding performance.</strong> PLOS Computational Biology 19(8): e1011362. <a href="https://doi.org/10.1371/journal.pcbi.1011362" target="_blank">https://doi.org/10.1371/journal.pcbi.1011362</a>.</p>
            <p>GRUS, Joel. <strong>Data science do zero: noções fundamentais com Python.</strong> Trad. Welington Nascimento. 2 ed. E-book. Rio de Janeiro: Alta Books, 2021.</p>
            <p>HAYKIN, Simon. <strong>Adaptive filter theory.</strong> 3 ed. Upper Saddle River, NJ: Prentice Hall, 1995.</p>
            <p>KANDEL, Eric R.; SCHWARTZ, James H.; JESSELL, Thomas M.; SIEGELBAUM, Steven A.; HUDSPETH, A. J. <strong>Princípios de neurociências</strong>. Trad. Ana Lúcia Severo Rodrigues et al. 5. ed. Porto Alegre: AMGH, 2014.</p>
            <p>VERY LARGE SCALE INTEGRATION. In: WIKIPEDIA. Disponível em <a href="https://en.wikipedia.org/wiki/Very_Large_Scale_Integration" target="_blank">https://en.wikipedia.org/wiki/Very_Large_Scale_Integration</a>. Acesso em 22 jan. 2024.</p>
            <a class="emoji" href="#top">[ 🔝 ]</a>
        </article>

        <hr>

        <article>
            <h2>Notas</h2>
            <p id="nota_1">[1] Uma rede neural artificial (ou apenas rede neural) é um modelo preditivo baseado na dinâmica do cérebro, que tem uma série de neurônios conectados. Cada um deles analisa as saídas dos outros neurônios ligados nele, faz um cálculo e, em seguida, dispara (se o valor calculado exceder um limite) ou não (se não). Portanto, as redes neurais artificiais são formadas por neurônios artificiais que executam cálculos semelhantes a partir de entradas. As redes neurais resolvem uma ampla variedade de problemas, como reconhecimento de caracteres manuscritos e detecção facial, e são muito usadas no aprendizado profundo, um dos subcampos mais inovadores do data science. No entanto, a maioria das redes neurais são “caixas-pretas” — analisar seus detalhes não explica como elas resolvem os problemas. Além disso, é difícil treinar grandes redes neurais. Para a maioria dos problemas típicos do início de carreira de um cientista de dados, elas não são a melhor opção. (GRUS, 2021, p. 245)<a class="linkdiscreto" href="#subtitulo_1"> [ 🔙 ]</a></p>
            <p id="nota_2">[2] Vide complemento #3 (dado, informação, conhecimento e competências).<a class="linkdiscreto" href="#subtitulo_1"> [ 🔙 ]</a></p>
            <p id="nota_3">[3] A palavra computar significa “fazer o cômputo de; calcular; orçar; contar; processar através de computadores”. Fonte: <a href="https://dicionario.priberam.org/computar">Dicionário Priberam da Língua Portuguesa</a>.<a class="linkdiscreto" href="#subtitulo_1"> [ 🔙 ]</a></p>
            <p id="nota_4">[4] Sobre o <strong>processamento em paralelo</strong>, das Neurociências colhe-se que, ao que parece, os comportamentos humanos de maior complexidade não decorrem da sinalização de um único neurônio, mas pela ação de muitos não necessariamente localizados na mesma região cortical (Kandel et al., 2014).
                <blockquote>
                    <p>
                        O envolvimento de vários grupos neurais ou rotas para transmitir uma informação similar é chamado <em>processamento em paralelo</em>. O processamento em paralelo também ocorre em uma única via quando diferentes neurônios nessa via executa ações similares simultaneamente. […] O campo da ciência computacional conhecido como inteligência artificial originalmente usou o processamento serial para simular os processos cognitivos do encéfalo […] Esses modelos seriais executavam muitas tarefas de forma adequada, inclusive jogar xadrez. Entretanto, eram muito ruins em outras tarefas que o encéfalo faz quase instantaneamente, com o reconhecimento de faces ou a compreensão do discurso. […] Nesses modelos [redes neurais], elementos do sistema processam a informação simultaneamente usando conexões de pró-ação e de retroalimentação. É interessante observar que, em sistemas com circuitos de retroalimentação é a atividade dinâmica do sistema que determina o desfecho do processamento, não as aferências ou condições iniciais. Modelos de redes neurais capturam bem a arquitetura altamente recorrente da maioria dos circuitos neurais reais e também a capacidade do encéfalo de funcionar na ausência de uma aferência sensorial específica vinda de fora do corpo […] Modelos de redes neurais também demonstram que a análise de elementos individuais de um sistema pode não ser suficiente para decodificar a <em>mensagem dos potenciais de ação</em>. De acordo com tal visão de redes neurais, o que faz o encéfalo ser um deslumbrante órgão que processa a informação não é a complexidade de seus neurônios, mas o fato de ter muitos elementos interconectados de várias formas complexas.&quot; (KANDEL et al., 2014, p. 32/33)
                        <br/><a class="linkdiscreto" href="#subtitulo_1_nota_4"> [ 🔙 ]</a>
                    </p>
                </blockquote>
            </p>
            <p id="nota_5">[5] Vide complemento #1 (plasticidade).<a class="linkdiscreto" href="#subtitulo_1_nota_5"> [ 🔙 ]</a></p>
            <p id="nota_6">[6] Nesse contexto, diz-se que uma rede neural é uma <strong>máquina adaptativa</strong> exatamente pela capacidade aprendizado (autoajuste) e adaptação a partir dos dados de entrada, o que permite o ajuste de parâmetros (pesos sinápticos) para obter o melhor desempenho na tarefa.<a class="linkdiscreto" href="#subtitulo_1_nota_6"> [ 🔙 ]</a></p>
            <p id="nota_7">[7] Sobre <strong>filtros adaptativos (<em>adaptive filter</em>)</strong>:
                <blockquote>
                    The term “filter” is often used to describe a device in the form of a piece of physical hardware or software that is applied to a set of noisy data in order to extract information about a prescribed quantity of interest. […] In any event, we may use a filter to perform three basic information-processing tasks:
                        <ol>
                            <li><em>Filtering</em>, which means the extraction of information about a quantity of interest at a time <math><mi>t</mi></math> by using data measured up to and including time <math><mi>t</mi></math>.</li>
                            <li><em>Smoothing</em>, which differs from filtering in that information about the quantity of interest need not to be available at time <math><mi>t</mi></math>, and data measured later than time <math><mi>t</mi></math> can be used in obtaining this information. This means that in the case of smoothing there is a <em>delay</em> in producing the result of interest. Since in the smoothing process we are able to use data obtained not only up to time <math><mi>t</mi></math> but also data obtained after time <math><mi>t</mi></math>, we would expect smoothing to be more accurate in some sense than filtering.</li>
                            <li><em>Prediction</em>, which is the forecasting side of information processing. The aim here is to derive information about what the quantity of interest will be like at some time <math><mi>t</mi><mo>+</mo><mi>T</mi></math> in the future, for some <math><mi>T</mi><mo>></mo><mn>0</mn></math>, by using data measured up to and including time <math><mi>t</mi></math>.<br> We may classify filters into linear and nonlinear. A filter is said to be <em>linear</em> if the filtered, smoothed, or predicted quantity at the output of the device is <em>a linear function of the observations applied to the filter input</em>. Otherwise, the filter is nonlinear. […] By such a device [an adaptive filter] we mean one that is self-designing in that the adaptive filter relies for its operation on a recursive algorithm, which makes it possible for the filter to perform satisfactorily in an environment where complete knowledge of the relevant signal characteristics is not available. (HAYKIN, 1995, p. 1/3)</li>
                            <a class="linkdiscreto" href="#subtitulo_1_nota_7"> [ 🔙 ]</a>
                        </ol>
                </blockquote>
            </p>            
            <p id="nota_8">[8] VLSI, do inglês <em>Very Large Scale Integration</em>, é um processo de fabricação de circuitos eletrônicos integrados com altíssima quantidade de transistores em um único chip.<a class="linkdiscreto" href="#subtitulo_1_1"> [ 🔙 ]</a></p>
            <p id="nota_9">[9] Vide complemento #2 (sistema nervoso, encéfalo e neurônio).<a class="linkdiscreto" href="#subtitulo_2"> [ 🔙 ]</a></p>
            <p id="nota_10">[10] A sinapse é uma região específica, ao passo que ao processo de comunicação entre neurônios dá-se o nome de transmissão sináptica (Kandel et al., 2004). Nesse sentido, “o local especializado em que um neurônio se comunica com outro é chamado de sinapse […]” (KANDEL et al., 2014, p. 157).<a class="linkdiscreto" href="#subtitulo_1_1_notas_10_11"> [ 🔙 ]</a></p>
            <p id="nota_11">[11] Vide complemento #2 (sistema nervoso, encéfalo e neurônio).<a class="linkdiscreto" href="#subtitulo_1_1_notas_10_11"> [ 🔙 ]</a></p>
            <p id="nota_12">[12] Em se tratando de peso sináptico, também referido como força sináptica, “[…] muitos modelos neurais estão equipados com processos dinâmicos que [se]reorganizam continuamente […] criam ou eliminam neurônios ou suas conexões […] ajustam as forças de conexões sinápticas existentes ou mudam outras propriedades dos neurônios. […] O termo peso sináptico frequentemente é utilizado para se referir à força de determinada conexão sináptica, enquanto o termo matriz de pesos sinápticos aplica-se ao conjunto de todos os pesos sinápticos em uma rede. A força da sinapse do neurônio <math><mi>j</mi></math> sobre o neurônio <math><mi>i</mi></math> é descrita como <math><msub><mi>W</mi><mi>ij</mi></msub></math>. Esse é o elemento da matriz de pesos localizado na intersecção da linha <math><mi>i</mi></math> com a coluna <math><mi>j</mi></math>.” (KANDEL et al., 2014, p. 1387). O fenômeno da modificação dos pesos sinápticos é consequência da plasticidade - <strong>regra de plasticidade sináptica</strong> -, que Kandel et al. (2014) argumenta que não deve se confundida com a <strong>regra da aprendizagem</strong>, embora sejam comumente utilizadas como sinônimas, pois aprendizado é a “[…] expressão do comportamento de uma rede e não de uma única sinapse” (KANDEL et al., 2014, p. 1387). Nesse sentido, a <strong>regra ou plasticidade <em>hebbiana</em></strong>, em alusão a Donald Hebb, ensina que “[…] as sinapses são modificadas com base na atividade temporalmente contígua dos neurônios pré e pós-sinápticos” (KANDEL et al., 2014, p. 1387). Conforme Bear et al. (2017, p. 878), “Donald Hebb propôs que cada sinapse individual se torna um pouco mais forte quando participa com sucesso no disparo de um neurônio pós-sináptico”, embora haja trabalhos no sentido de que a mudança do peso sináptico esteja mais proximamente relacionada ao neurônio pré-sináptico, apenas (Gallinaro; Scholl; Clopath, 2023).<a class="linkdiscreto" href="#subtitulo_3"> [ 🔙 ]</a></p>
            <p id="nota_13">[13] Em referência ao potencial de ação da célula biológica.<a class="linkdiscreto" href="#subtitulo_3_nota_13"> [ 🔙 ]</a></p>
            <p id="nota_14">[14] No livro, este subtítulo está nível hierárquico superior, isto é, como a seção autônoma de número 4. Contudo, para melhor compreensão, optei por incluí-lo como parte da seção 3, que trata dos modelos de neurônio, tendo em vista que, assim como o diagrama em blocos (figura 3) os grafos são uma das formas de representar graficamente uma rede neural.<a class="linkdiscreto" href="#subtitulo_3_3"> [ 🔙 ]</a></p>
            <p id="nota_15">[15] Um grafo é uma estrutura matemática utilizada para modelar relacionamentos entre pares de objetos. Esses objetos são os vértices, também chamados de pontos ou nós, e seus relacionamentos são representados por arestas, que os conectam. Há grafos dirigidos/direcionados ou não dirigidos/não direcionados, a depender da existência ou não de sentido predefinido para as arestas. Sua aplicação na Ciência da Computação será abordada em complemento específico, a ser elaborado futuramente.<a class="linkdiscreto" href="#subtitulo_3_3"> [ 🔙 ]</a></p>
            <p id="nota_16">[16] Esta subdivisão não consta do livro, mas foi criada para melhor didática.<a class="linkdiscreto" href="#subtitulo_3_4"> [ 🔙 ]</a></p>
            <p id="nota_17">[17] "Sistemas dinâmicos são sistemas fora do equilíbrio, caracterizados por estados que mudam com o tempo. São usados para modelar e fazer previsões de sistemas físicos, biológicos, financeiros, etc." (AGUIAR, 2005, p. 3). Aguiar (2015) ainda destaca que a definição de um sistema dinâmico exige três requisitos: espaço de estados, equações de movimento e medida de distância. E os classifica em discretos, contínuos, campos, autômato celular e redes complexas; lineares ou não lineares; conservativos ou dissipativos; autômatos ou não autômatos; com ou sem retardo; e determinísticos ou probabilísticos.<a class="linkdiscreto" href="#subtitulo_5"> [ 🔙 ]</a></p>
            <p id="nota_18">[18] "[...] alguns modelos de redes neurais tentaram incluir interações entre sinais globais de uma fonte central e sinais locais, como fator de modificação sináptica." (KANDEL et al., 2014, p. 1387).<a class="linkdiscreto" href="#subtitulo_5"> [ 🔙 ]</a></p>
            <p id="nota_19">[19] "[...] o conhecimento sobre o domínio do problema de interesse é adquirido pela rede de uma forma relativamente simples e direta através de treinamento. O conhecimento assim adquirido é representado em uma forma compacta e distribuída como pesos através de conexões sinápticas da rede. Enquanto esta forma de representação de conhecimento permite que a rede neural se adapte e generalize, infelizmente a rede neural sofre da incapacidade inerente para explicar, de uma forma abrangente, o processo computacional através do qual a rede toma uma decisão ou apresenta suas saídas." (HAYKIN, 2001, p. 59)<a class="linkdiscreto" href="#subtitulo_7"> [ 🔙 ]</a></p>
            <p id="nota_20">[20] No contexto de redes neurais, <strong>ruídos</strong> são sinais indesejados, irrelevantes ou imprecisos que interferem na qualidade dos dados. Nesse sentido, vide a nota #7, sobre filtros adaptativos.<a class="linkdiscreto" href="#subtitulo_7_nota_20"> [ 🔙 ]</a></p>
            <p id="nota_21">[21] De forma simplificada, o campo local induzido é a soma ponderada dos sinais de entrada e determina se haverá ou não ativação do neurônio e consequente disparo do sinal de saída.<a class="linkdiscreto" href="#subtitulo_7_2_nota_21"> [ 🔙 ]</a></p>
            <p id="nota_22">[22] Na 2a edição do livro, o capítulo 2 era dedicado integralmente aos processos de aprendizagem. Entretanto, na 3a edição, o tema é abordado em dois tópicos da Introdução do livro e em menor extensão. Por esse motivo, criei uma subseção específica para tratar de aspectos conceituais que não foram abordados na nova edição ou que o foram superficialmente mais adiante.<a class="linkdiscreto" href="#subtitulo_8"> [ 🔙 ]</a></p>
            <p id="nota_23">[23] O <em>bias</em> (viés) é uma constante independente que pode ser aplicada à soma ponderada dos sinais de entrada, antes de serem submetidos à função de ativação, de modo a influenciar/deslocar o valor de saída do neurônio. Ao apontar para melhores representações dos dados pelo refinamento do liminar (*threshold*) de ativação, ele auxilia a rede neural no processo de aprendizagem por meio do aumento da efetividade do [disparo do] neurônio. Vide [tópico 3 (modelos de neurônio artificial)](#3-modelos-de-neurônio-artificial) para mais detalhes.<a class="linkdiscreto" href="#subtitulo_8_1"> [ 🔙 ]</a></p>
            <p id="nota_24">[24] A <strong>pseudotemperatura</strong> é um parâmetro utilizado para controlar o nível de ruído do sistema e, por conseguinte, a probabilidade de disparo do neurônio. Nesse sentido, vide o tópico <a href="#subtitulo_3_2">3.2 Modelo estocástico de neurônio</a>.<a class="linkdiscreto" href="#subtitulo_8_1_1_5_nota_24"> [ 🔙 ]</a></p>
            <a class="emoji" href="#top">[ 🔝 ]</a>
        </article>
    </main>
</body>

<footer>
    <p>Projeto NeuroBit</p>
        <p class="linkdiscreto">
            <a class="social" href="https://github.com/paulorobertovrc" target="_blank">
                <svg width="24px" height="24px" viewBox="0 0 20 20" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" fill="#ffffff"><g id="SVGRepo_bgCarrier" stroke-width="0"></g><g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g><g id="SVGRepo_iconCarrier"> <title>github [#142]</title> <desc>Created with Sketch.</desc> <defs> </defs> <g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"> <g id="Dribbble-Light-Preview" transform="translate(-140.000000, -7559.000000)" fill="#fff"> <g id="icons" transform="translate(56.000000, 160.000000)"> <path d="M94,7399 C99.523,7399 104,7403.59 104,7409.253 C104,7413.782 101.138,7417.624 97.167,7418.981 C96.66,7419.082 96.48,7418.762 96.48,7418.489 C96.48,7418.151 96.492,7417.047 96.492,7415.675 C96.492,7414.719 96.172,7414.095 95.813,7413.777 C98.04,7413.523 100.38,7412.656 100.38,7408.718 C100.38,7407.598 99.992,7406.684 99.35,7405.966 C99.454,7405.707 99.797,7404.664 99.252,7403.252 C99.252,7403.252 98.414,7402.977 96.505,7404.303 C95.706,7404.076 94.85,7403.962 94,7403.958 C93.15,7403.962 92.295,7404.076 91.497,7404.303 C89.586,7402.977 88.746,7403.252 88.746,7403.252 C88.203,7404.664 88.546,7405.707 88.649,7405.966 C88.01,7406.684 87.619,7407.598 87.619,7408.718 C87.619,7412.646 89.954,7413.526 92.175,7413.785 C91.889,7414.041 91.63,7414.493 91.54,7415.156 C90.97,7415.418 89.522,7415.871 88.63,7414.304 C88.63,7414.304 88.101,7413.319 87.097,7413.247 C87.097,7413.247 86.122,7413.234 87.029,7413.87 C87.029,7413.87 87.684,7414.185 88.139,7415.37 C88.139,7415.37 88.726,7417.2 91.508,7416.58 C91.513,7417.437 91.522,7418.245 91.522,7418.489 C91.522,7418.76 91.338,7419.077 90.839,7418.982 C86.865,7417.627 84,7413.783 84,7409.253 C84,7403.59 88.478,7399 94,7399" id="github-[#142]"> </path> </g> </g> </g> </g></svg>
            </a>
            <a class="social" href="https://www.instagram.com/pauloroberto.dev" target="_blank">
                <svg width="24px" height="24px" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" stroke="#FFFFFF"><g id="SVGRepo_bgCarrier" stroke-width="0"></g><g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g><g id="SVGRepo_iconCarrier"> <path fill-rule="evenodd" clip-rule="evenodd" d="M12 18C15.3137 18 18 15.3137 18 12C18 8.68629 15.3137 6 12 6C8.68629 6 6 8.68629 6 12C6 15.3137 8.68629 18 12 18ZM12 16C14.2091 16 16 14.2091 16 12C16 9.79086 14.2091 8 12 8C9.79086 8 8 9.79086 8 12C8 14.2091 9.79086 16 12 16Z" fill="#FFFFFF"></path> <path d="M18 5C17.4477 5 17 5.44772 17 6C17 6.55228 17.4477 7 18 7C18.5523 7 19 6.55228 19 6C19 5.44772 18.5523 5 18 5Z" fill="#FFFFFF"></path> <path fill-rule="evenodd" clip-rule="evenodd" d="M1.65396 4.27606C1 5.55953 1 7.23969 1 10.6V13.4C1 16.7603 1 18.4405 1.65396 19.7239C2.2292 20.8529 3.14708 21.7708 4.27606 22.346C5.55953 23 7.23969 23 10.6 23H13.4C16.7603 23 18.4405 23 19.7239 22.346C20.8529 21.7708 21.7708 20.8529 22.346 19.7239C23 18.4405 23 16.7603 23 13.4V10.6C23 7.23969 23 5.55953 22.346 4.27606C21.7708 3.14708 20.8529 2.2292 19.7239 1.65396C18.4405 1 16.7603 1 13.4 1H10.6C7.23969 1 5.55953 1 4.27606 1.65396C3.14708 2.2292 2.2292 3.14708 1.65396 4.27606ZM13.4 3H10.6C8.88684 3 7.72225 3.00156 6.82208 3.0751C5.94524 3.14674 5.49684 3.27659 5.18404 3.43597C4.43139 3.81947 3.81947 4.43139 3.43597 5.18404C3.27659 5.49684 3.14674 5.94524 3.0751 6.82208C3.00156 7.72225 3 8.88684 3 10.6V13.4C3 15.1132 3.00156 16.2777 3.0751 17.1779C3.14674 18.0548 3.27659 18.5032 3.43597 18.816C3.81947 19.5686 4.43139 20.1805 5.18404 20.564C5.49684 20.7234 5.94524 20.8533 6.82208 20.9249C7.72225 20.9984 8.88684 21 10.6 21H13.4C15.1132 21 16.2777 20.9984 17.1779 20.9249C18.0548 20.8533 18.5032 20.7234 18.816 20.564C19.5686 20.1805 20.1805 19.5686 20.564 18.816C20.7234 18.5032 20.8533 18.0548 20.9249 17.1779C20.9984 16.2777 21 15.1132 21 13.4V10.6C21 8.88684 20.9984 7.72225 20.9249 6.82208C20.8533 5.94524 20.7234 5.49684 20.564 5.18404C20.1805 4.43139 19.5686 3.81947 18.816 3.43597C18.5032 3.27659 18.0548 3.14674 17.1779 3.0751C16.2777 3.00156 15.1132 3 13.4 3Z" fill="#FFFFFF"></path> </g></svg>
            </a>
            <a class="social" href="https://www.linkedin.com/in/paulorobertovrc" target="_blank">
                <svg width="27px" height="27px" viewBox="0 0 21 21" fill="none" xmlns="http://www.w3.org/2000/svg"><g id="SVGRepo_bgCarrier" stroke-width="0"></g><g id="SVGRepo_tracerCarrier" stroke-linecap="round" stroke-linejoin="round"></g><g id="SVGRepo_iconCarrier"> <path d="M18.72 3.99997H5.37C5.19793 3.99191 5.02595 4.01786 4.86392 4.07635C4.70189 4.13484 4.55299 4.22471 4.42573 4.34081C4.29848 4.45692 4.19537 4.59699 4.12232 4.75299C4.04927 4.909 4.0077 5.07788 4 5.24997V18.63C4.01008 18.9901 4.15766 19.3328 4.41243 19.5875C4.6672 19.8423 5.00984 19.9899 5.37 20H18.72C19.0701 19.9844 19.4002 19.8322 19.6395 19.5761C19.8788 19.32 20.0082 18.9804 20 18.63V5.24997C20.0029 5.08247 19.9715 4.91616 19.9078 4.76122C19.8441 4.60629 19.7494 4.466 19.6295 4.34895C19.5097 4.23191 19.3672 4.14059 19.2108 4.08058C19.0544 4.02057 18.8874 3.99314 18.72 3.99997ZM9 17.34H6.67V10.21H9V17.34ZM7.89 9.12997C7.72741 9.13564 7.5654 9.10762 7.41416 9.04768C7.26291 8.98774 7.12569 8.89717 7.01113 8.78166C6.89656 8.66615 6.80711 8.5282 6.74841 8.37647C6.6897 8.22474 6.66301 8.06251 6.67 7.89997C6.66281 7.73567 6.69004 7.57169 6.74995 7.41854C6.80986 7.26538 6.90112 7.12644 7.01787 7.01063C7.13463 6.89481 7.2743 6.80468 7.42793 6.74602C7.58157 6.68735 7.74577 6.66145 7.91 6.66997C8.07259 6.66431 8.2346 6.69232 8.38584 6.75226C8.53709 6.8122 8.67431 6.90277 8.78887 7.01828C8.90344 7.13379 8.99289 7.27174 9.05159 7.42347C9.1103 7.5752 9.13699 7.73743 9.13 7.89997C9.13719 8.06427 9.10996 8.22825 9.05005 8.3814C8.99014 8.53456 8.89888 8.6735 8.78213 8.78931C8.66537 8.90513 8.5257 8.99526 8.37207 9.05392C8.21843 9.11259 8.05423 9.13849 7.89 9.12997ZM17.34 17.34H15V13.44C15 12.51 14.67 11.87 13.84 11.87C13.5822 11.8722 13.3313 11.9541 13.1219 12.1045C12.9124 12.2549 12.7546 12.4664 12.67 12.71C12.605 12.8926 12.5778 13.0865 12.59 13.28V17.34H10.29V10.21H12.59V11.21C12.7945 10.8343 13.0988 10.5225 13.4694 10.3089C13.84 10.0954 14.2624 9.98848 14.69 9.99997C16.2 9.99997 17.34 11 17.34 13.13V17.34Z" fill="#FFFFFF"></path> </g></svg>
            </a>
        </p>
</footer>
